{"pageProps":{"tag":"CNN","postMetas":[{"rawMarkdown":"---\ntitle: \"ILSVRC 2017 画像分類 Top の手法 Squeeze-and-Excitation Networks\"\ndate: 2018-12-13T22:25:45+09:00\ntags: [\"画像処理\", \"ComputerVision\", \"MachineLearning\", \"DeepLearning\", \"CNN\"]\nurl: https://qiita.com/agatan/items/8cf2566908228eaa5450\n---\n\nILSVRC 2017 の画像分類タスクでは Squeeze-and-Excitation という手法が 1 位を記録しました。\nシンプルなアイディア・実装で、既存モデルの拡張にも利用できるうえ、精度も 2016 年の top 1 と比べてエラー率を約 25% 減らすという大きな成果をあげています。\n\n![image.png](https://qiita-image-store.s3.amazonaws.com/0/39030/20b939b8-c65b-ce06-4525-37ccfe19c7a2.png)\n\n### Reference\n\n- Jie Hu, et al., https://arxiv.org/pdf/1709.01507.pdf\n\n文中の図表は論文から引用しています。\n\nこの記事は、Wantedly の勉強会で取り上げられた論文・技術をまとめたものです。\n[2018 年に読んだ機械学習系論文・技術まとめ at Wantedly Advent Calendar 2018 - Qiita](https://qiita.com/advent-calendar/2018/wantedly_ml)\n\n## Squeeze and Excitation\n\nこの論文では、SE block というブロックを提案しています。\nSE block は特定のネットワーク全体の設計の提案ではなく、ネットワーク中の 1 component として振る舞うものです。\nSE block を既存のいろいろなネットワークやモジュール（ResNet、Inception、...）に組み込むことで精度が向上することを実験で確かめています。\n\nSE block は非常に実装が簡単なので先に実装を見てしまったほうがわかりやすいかもしれません。\n\n```python\ndef se_block(input, channels):\n    \"\"\"\n    Args:\n        input: (N, H, W, C)\n        channels: C\n    Returns:\n        tensor: (N, H, W, C)\n    \"\"\"\n    # Squeeze\n    x = GlobalAveragePooling2D()(input)  # (N, C)\n    # Excitation\n    x = Dense(channels // 16, activation='relu')(x)\n    x = Dense(channels, activation='sigmoid')(x) # (N, C)\n    return Multiply()([input, x])\n```\n\nSE block は、通常の convolution の出力をそのまま使うのではなく、 **各 channel の出力を重み付けして使う** ようにすることで、チャンネル間の関係性の学習を可能にするブロックです。\n\n### Squeeze\n\n既存のモデルは、convolution と activation を重ねることで、局所的な特徴を獲得していきます。\n層が深くなったり pooling したりすると、局所的といいつつも広い視野を持っていくことになりますが、視野を一歩こえた先の情報などはまったく考慮できず、画像全体におけるチャンネル間の関係性を表すことはできません。\nそこで、画像全体の特徴を活用するために、 global average pooling を利用します。（Spatial Squeeze）\n\n### Excitation\n\nそうして得た「画像全体のチャンネルの状況」をいくつかの layer に通したのち、sigmoid に通します。\n最後にブロックに入力されてきた値 `input` に、 sigmoid 関数を通して 0~1 の範囲に収めた「各チャンネルの重み」を掛けて出力しています。\nこの部分が Excitation とよばれる部分です。\n\n## 既存モデルへの組み込み\n\nSE block は既存のモデルへの組み込みが容易であることも大きな強みです。\nいくつかの組み込み方が提案・実験されています。\n\n<table>\n<tr>\n<td>\n<img src=\"https://qiita-image-store.s3.amazonaws.com/0/39030/76082379-9db4-4f02-7236-355f6804908b.png\">\n</td>\n<td>\n<img src=\"https://qiita-image-store.s3.amazonaws.com/0/39030/4c3fa967-234c-57ee-36a9-1c15fca7c603.png\">\n</td>\n</tr>\n</table>\n\n組み込み方もシンプルで簡単に試せるのですばらしいですね。\n\n## まとめと感想\n\nかなりいろんなセットアップで実験をしているので、詳細は論文を参照ください。\nWantedly People で使われているモデルにも実験的に組みこんでみたところ、確かに数%の改善が確認できました。\nこの論文の続編的なものとして、segmentation タスクなどの fully convolutional networks 用の SE block 亜種が提案されています。\nこの advent calendar のどこかでそちらの紹介もできればと思います。\n","contentMarkdown":"\nILSVRC 2017 の画像分類タスクでは Squeeze-and-Excitation という手法が 1 位を記録しました。\nシンプルなアイディア・実装で、既存モデルの拡張にも利用できるうえ、精度も 2016 年の top 1 と比べてエラー率を約 25% 減らすという大きな成果をあげています。\n\n![image.png](https://qiita-image-store.s3.amazonaws.com/0/39030/20b939b8-c65b-ce06-4525-37ccfe19c7a2.png)\n\n### Reference\n\n- Jie Hu, et al., https://arxiv.org/pdf/1709.01507.pdf\n\n文中の図表は論文から引用しています。\n\nこの記事は、Wantedly の勉強会で取り上げられた論文・技術をまとめたものです。\n[2018 年に読んだ機械学習系論文・技術まとめ at Wantedly Advent Calendar 2018 - Qiita](https://qiita.com/advent-calendar/2018/wantedly_ml)\n\n## Squeeze and Excitation\n\nこの論文では、SE block というブロックを提案しています。\nSE block は特定のネットワーク全体の設計の提案ではなく、ネットワーク中の 1 component として振る舞うものです。\nSE block を既存のいろいろなネットワークやモジュール（ResNet、Inception、...）に組み込むことで精度が向上することを実験で確かめています。\n\nSE block は非常に実装が簡単なので先に実装を見てしまったほうがわかりやすいかもしれません。\n\n```python\ndef se_block(input, channels):\n    \"\"\"\n    Args:\n        input: (N, H, W, C)\n        channels: C\n    Returns:\n        tensor: (N, H, W, C)\n    \"\"\"\n    # Squeeze\n    x = GlobalAveragePooling2D()(input)  # (N, C)\n    # Excitation\n    x = Dense(channels // 16, activation='relu')(x)\n    x = Dense(channels, activation='sigmoid')(x) # (N, C)\n    return Multiply()([input, x])\n```\n\nSE block は、通常の convolution の出力をそのまま使うのではなく、 **各 channel の出力を重み付けして使う** ようにすることで、チャンネル間の関係性の学習を可能にするブロックです。\n\n### Squeeze\n\n既存のモデルは、convolution と activation を重ねることで、局所的な特徴を獲得していきます。\n層が深くなったり pooling したりすると、局所的といいつつも広い視野を持っていくことになりますが、視野を一歩こえた先の情報などはまったく考慮できず、画像全体におけるチャンネル間の関係性を表すことはできません。\nそこで、画像全体の特徴を活用するために、 global average pooling を利用します。（Spatial Squeeze）\n\n### Excitation\n\nそうして得た「画像全体のチャンネルの状況」をいくつかの layer に通したのち、sigmoid に通します。\n最後にブロックに入力されてきた値 `input` に、 sigmoid 関数を通して 0~1 の範囲に収めた「各チャンネルの重み」を掛けて出力しています。\nこの部分が Excitation とよばれる部分です。\n\n## 既存モデルへの組み込み\n\nSE block は既存のモデルへの組み込みが容易であることも大きな強みです。\nいくつかの組み込み方が提案・実験されています。\n\n<table>\n<tr>\n<td>\n<img src=\"https://qiita-image-store.s3.amazonaws.com/0/39030/76082379-9db4-4f02-7236-355f6804908b.png\">\n</td>\n<td>\n<img src=\"https://qiita-image-store.s3.amazonaws.com/0/39030/4c3fa967-234c-57ee-36a9-1c15fca7c603.png\">\n</td>\n</tr>\n</table>\n\n組み込み方もシンプルで簡単に試せるのですばらしいですね。\n\n## まとめと感想\n\nかなりいろんなセットアップで実験をしているので、詳細は論文を参照ください。\nWantedly People で使われているモデルにも実験的に組みこんでみたところ、確かに数%の改善が確認できました。\nこの論文の続編的なものとして、segmentation タスクなどの fully convolutional networks 用の SE block 亜種が提案されています。\nこの advent calendar のどこかでそちらの紹介もできればと思います。\n","slug":"ILSVRC_2017_画像分類_Top_の手法_Squeeze-and-Excitation_Networks","title":"ILSVRC 2017 画像分類 Top の手法 Squeeze-and-Excitation Networks","timestamp":1544707545000,"tags":["画像処理","ComputerVision","MachineLearning","DeepLearning","CNN"]}]},"__N_SSG":true}