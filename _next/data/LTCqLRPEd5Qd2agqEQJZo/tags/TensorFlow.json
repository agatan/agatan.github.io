{"pageProps":{"tag":"TensorFlow","postMetas":[{"rawMarkdown":"---\ntitle: \"【論文紹介】Concurrent Spatial and Channel Squeeze & Excitation in Fully Convolutional Networks\"\ndate: 2019-01-04T14:51:07+09:00\ntags: [\"Python\", \"DeepLearning\", \"Keras\", \"TensorFlow\", \"論文読み\"]\nurl: https://qiita.com/agatan/items/61546d71e7ea7ad14b11\n---\n\nFully Convolutional Network (FCN) の性能を enhance する Concurrent Spatial and Channel Squeeze & Excitation (scSE) というモジュールを提案した論文です。\n既存の良いとされてきたモデルたちに計算量をそこまで増やさずに & 簡単に組み込むことができ、 Image Segmentation などのタスクで性能を向上させることができます。\n\n[ILSVRC 2017 画像分類 Top の手法 Squeeze-and-Excitation Networks - Qiita](https://qiita.com/agatan/items/8cf2566908228eaa5450) で紹介した SE モジュールの後継にあたります。\n\n![image.png](https://qiita-image-store.s3.amazonaws.com/0/39030/f606f8d0-9510-f251-31d8-e9091ed031b9.png)\n\n## Reference\n\n- Abhijit Guha Roy, et al., MICCAI 2018\n- https://arxiv.org/abs/1803.02579\n\n文中の図表は論文から引用しています。\n\nこの記事は、Wantedly の勉強会で取り上げられた論文・技術をまとめたものです。\n[2018 年に読んだ機械学習系論文・技術まとめ at Wantedly Advent Calendar 2018 - Qiita](https://qiita.com/advent-calendar/2018/wantedly_ml)\n\n## Squeeze and Excitation を Image Segmentation に応用する\n\nSqueeze and Excitation (SE) モジュールは、[Squeeze-and-Excitation Networks](https://arxiv.org/abs/1709.01507) で提案されたもので、 ILSVRC 2017 でトップのスコアを記録しています。\nSE は Channel 間の関係性を考慮できるようにしたい、というモチベーションで、 チャンネルごとに画像全体の activation の平均を取り（Squeeze)、それをもとにチャンネル間の Attention をとる（Excitation）というものでした。（[ILSVRC 2017 画像分類 Top の手法 Squeeze-and-Excitation Networks - Qiita](https://qiita.com/agatan/items/8cf2566908228eaa5450)）\n本論文ではこのオリジナルの SE モジュールのことを channel SE (Spatial Squeeze and Channel Excitation, cSE) と呼んでいます。\n\n```python\nfrom tensorflow.python.keras.layers import GlovelAveragePooling2D, Dense, multiply\n\ndef spatial_squeeze_and_channel_excitation(x, ch, ratio=16):\n    squeeze = GlobalAveragePooling2D()(x)\n    z = Dense(ch // ratio, activation='relu')(squeeze)\n    excitation = Dense(ch, activation='sigmoid')(x)\n    return multiply([x, excitation])\n```\n\n本論文では Image Classification の性能を大きく向上した SE モジュールを、 Image Segmentation に応用することを考えます。\nImage Segmentation のタスクでは、Fully Convolutional な Architecture がよく採用されます。\nこの論文では、U-Net[^1] やそこから派生した SkipDeconv-Net[^2]， Fully Convolutional DenseNet[^3] などに対して SE モジュール的な考え方で性能を向上できないか実験しています。\n\n[^1]: Ronneberger O, Fischer P, Brox T. U-net: Convolutional networks for biomedical image segmentation. In Proc. MICCAI, Springer 2015, pp. 234-241.\n[^2]: Roy, A.G., Conjeti, S., Sheet, D., Katouzian, A., Navab, N. and Wachinger, C., 2017, September. Error Corrective Boosting for Learning Fully Convolutional Networks with Limited Data. In MICCAI, pp. 231-239, Springer.\n[^3]: J ́egou, S., Drozdzal, M., Vazquez, D., Romero, A. and Bengio, Y., 2017, July. The one hundred layers tiramisu: Fully convolutional densenets for semantic segmentation. In CVPR Workshop, pp. 1175-1183, IEEE.\n\nが、実際に SE モジュールをこれらの FCN に組み込んでみると、 Image Classification のときよりも性能が上がりづらいという結果が得られています。\nこの論文では、 「Image Segmentation は pixel-wise の情報が重要であり、チャンネルごとに画像全体から平均を取る cSE ではピクセル単位の情報をうまく enhance できていないのでは」という仮説を立てています。\n\n## Channel Squeeze and Spatial Excitation Block (sSE)\n\nそこでこの論文で提案されているので、 sSE です。\n名前のとおりですが、 Channel 方向に Squeeze し、Pixel ごとに Excitation を計算します。\ncSE は画像全体（Spatial）で Squeeze し、Channel ごとの Excitation を計算しているので、その逆をやっているというイメージです。\n\n<img src=\"https://qiita-image-store.s3.amazonaws.com/0/39030/7c6f2822-ff51-c4f6-2d3f-6c0422dca3fa.png\" width=\"60%\">\n\n実装はものすごく単純です。以下に `tf.keras` をつかった場合の実装例を載せます。\n\n```python\nimport tensorflow as tf\n\ndef channel_squeeze_and_spatial_excitation(x):\n    excitation = tf.keras.layers.Conv2D(filters=1, kernel_size=1, activation='sigmoid')(x)\n    return tf.keras.layers.multiply([x, excitation])\n```\n\n`Conv2D(filters=1, kernel_size=1, activation='sigmoid')` で、pixel ごとに 1 チャンネルの値を 0~1 で出力させます。\nこれが「ある pixel における excitation」になります。出力は、入力である feature map と excitation の element-wise な積です。\n\n## Spatial and Channel Squeeze & Excitation (scSE)\n\nまた、提案手法である sSE とオリジナルの cSE は conflict しないので、両方採用してしまおう、というのが scSE です。\n\n<img src=\"https://qiita-image-store.s3.amazonaws.com/0/39030/fcbc2c76-3947-f587-eb8a-4422b4a28b7e.png\" width=\"70%\">\n\nこの図の上部が sSE、下部が cSE です。同じ入力からそれぞれを計算し、最後に単純に足し算したものを scSE と呼んでいます。\n\n```python\ndef _concurrent_spartial_and_channel_se(input_feature, ch, ratio=16):\n    cse = _spatial_squeeze_and_channel_excitation(input_feature, ch, ratio=ratio)\n    sse = _channel_squeeze_and_spatial_excitation(input_feature)\n    return tf.keras.layers.Add()([cse, sse])\n```\n\nこの論文で実験に使われている U-Net の場合、 scSE を使った場合でも計算量は 1.5% 程度の増加で済んでいます。\n\n## Experiments\n\nいくつかのネットワークについて、「素の状態」「cSE」「sSE」「scSE」の 4 パターンで実験しています。\nここでは DenseNet のケースについてまとめた図を論文中の Fig.2 から引用します。\n詳細や全体像は論文を参照してください。\n\n![image.png](https://qiita-image-store.s3.amazonaws.com/0/39030/31a9cee5-5d22-b682-1400-b3f98bfe5ae3.png)\n\n横軸はタスク名です。\nタスクにもよりますが、概ね `DenseNets` < `DenseNets + cSE` < `DenseNets + sSE` < `DenseNets + scSE` になっているように見えます。\ncSE だけをいれると素の状態より性能が悪くなっているケースも見られるのが面白いところです。\n\n## まとめと感想\n\nタスクの特性を見て仮説を立て、実際にそれがうまくハマっているという論文で、よみやすいし納得感のある論文でした。\n実装の容易さと試しやすさ（既存モデルへ着脱できる）がうれしい手法で、実際に活用しているモデルに組み込まれています。\n","contentMarkdown":"\nFully Convolutional Network (FCN) の性能を enhance する Concurrent Spatial and Channel Squeeze & Excitation (scSE) というモジュールを提案した論文です。\n既存の良いとされてきたモデルたちに計算量をそこまで増やさずに & 簡単に組み込むことができ、 Image Segmentation などのタスクで性能を向上させることができます。\n\n[ILSVRC 2017 画像分類 Top の手法 Squeeze-and-Excitation Networks - Qiita](https://qiita.com/agatan/items/8cf2566908228eaa5450) で紹介した SE モジュールの後継にあたります。\n\n![image.png](https://qiita-image-store.s3.amazonaws.com/0/39030/f606f8d0-9510-f251-31d8-e9091ed031b9.png)\n\n## Reference\n\n- Abhijit Guha Roy, et al., MICCAI 2018\n- https://arxiv.org/abs/1803.02579\n\n文中の図表は論文から引用しています。\n\nこの記事は、Wantedly の勉強会で取り上げられた論文・技術をまとめたものです。\n[2018 年に読んだ機械学習系論文・技術まとめ at Wantedly Advent Calendar 2018 - Qiita](https://qiita.com/advent-calendar/2018/wantedly_ml)\n\n## Squeeze and Excitation を Image Segmentation に応用する\n\nSqueeze and Excitation (SE) モジュールは、[Squeeze-and-Excitation Networks](https://arxiv.org/abs/1709.01507) で提案されたもので、 ILSVRC 2017 でトップのスコアを記録しています。\nSE は Channel 間の関係性を考慮できるようにしたい、というモチベーションで、 チャンネルごとに画像全体の activation の平均を取り（Squeeze)、それをもとにチャンネル間の Attention をとる（Excitation）というものでした。（[ILSVRC 2017 画像分類 Top の手法 Squeeze-and-Excitation Networks - Qiita](https://qiita.com/agatan/items/8cf2566908228eaa5450)）\n本論文ではこのオリジナルの SE モジュールのことを channel SE (Spatial Squeeze and Channel Excitation, cSE) と呼んでいます。\n\n```python\nfrom tensorflow.python.keras.layers import GlovelAveragePooling2D, Dense, multiply\n\ndef spatial_squeeze_and_channel_excitation(x, ch, ratio=16):\n    squeeze = GlobalAveragePooling2D()(x)\n    z = Dense(ch // ratio, activation='relu')(squeeze)\n    excitation = Dense(ch, activation='sigmoid')(x)\n    return multiply([x, excitation])\n```\n\n本論文では Image Classification の性能を大きく向上した SE モジュールを、 Image Segmentation に応用することを考えます。\nImage Segmentation のタスクでは、Fully Convolutional な Architecture がよく採用されます。\nこの論文では、U-Net[^1] やそこから派生した SkipDeconv-Net[^2]， Fully Convolutional DenseNet[^3] などに対して SE モジュール的な考え方で性能を向上できないか実験しています。\n\n[^1]: Ronneberger O, Fischer P, Brox T. U-net: Convolutional networks for biomedical image segmentation. In Proc. MICCAI, Springer 2015, pp. 234-241.\n[^2]: Roy, A.G., Conjeti, S., Sheet, D., Katouzian, A., Navab, N. and Wachinger, C., 2017, September. Error Corrective Boosting for Learning Fully Convolutional Networks with Limited Data. In MICCAI, pp. 231-239, Springer.\n[^3]: J ́egou, S., Drozdzal, M., Vazquez, D., Romero, A. and Bengio, Y., 2017, July. The one hundred layers tiramisu: Fully convolutional densenets for semantic segmentation. In CVPR Workshop, pp. 1175-1183, IEEE.\n\nが、実際に SE モジュールをこれらの FCN に組み込んでみると、 Image Classification のときよりも性能が上がりづらいという結果が得られています。\nこの論文では、 「Image Segmentation は pixel-wise の情報が重要であり、チャンネルごとに画像全体から平均を取る cSE ではピクセル単位の情報をうまく enhance できていないのでは」という仮説を立てています。\n\n## Channel Squeeze and Spatial Excitation Block (sSE)\n\nそこでこの論文で提案されているので、 sSE です。\n名前のとおりですが、 Channel 方向に Squeeze し、Pixel ごとに Excitation を計算します。\ncSE は画像全体（Spatial）で Squeeze し、Channel ごとの Excitation を計算しているので、その逆をやっているというイメージです。\n\n<img src=\"https://qiita-image-store.s3.amazonaws.com/0/39030/7c6f2822-ff51-c4f6-2d3f-6c0422dca3fa.png\" width=\"60%\">\n\n実装はものすごく単純です。以下に `tf.keras` をつかった場合の実装例を載せます。\n\n```python\nimport tensorflow as tf\n\ndef channel_squeeze_and_spatial_excitation(x):\n    excitation = tf.keras.layers.Conv2D(filters=1, kernel_size=1, activation='sigmoid')(x)\n    return tf.keras.layers.multiply([x, excitation])\n```\n\n`Conv2D(filters=1, kernel_size=1, activation='sigmoid')` で、pixel ごとに 1 チャンネルの値を 0~1 で出力させます。\nこれが「ある pixel における excitation」になります。出力は、入力である feature map と excitation の element-wise な積です。\n\n## Spatial and Channel Squeeze & Excitation (scSE)\n\nまた、提案手法である sSE とオリジナルの cSE は conflict しないので、両方採用してしまおう、というのが scSE です。\n\n<img src=\"https://qiita-image-store.s3.amazonaws.com/0/39030/fcbc2c76-3947-f587-eb8a-4422b4a28b7e.png\" width=\"70%\">\n\nこの図の上部が sSE、下部が cSE です。同じ入力からそれぞれを計算し、最後に単純に足し算したものを scSE と呼んでいます。\n\n```python\ndef _concurrent_spartial_and_channel_se(input_feature, ch, ratio=16):\n    cse = _spatial_squeeze_and_channel_excitation(input_feature, ch, ratio=ratio)\n    sse = _channel_squeeze_and_spatial_excitation(input_feature)\n    return tf.keras.layers.Add()([cse, sse])\n```\n\nこの論文で実験に使われている U-Net の場合、 scSE を使った場合でも計算量は 1.5% 程度の増加で済んでいます。\n\n## Experiments\n\nいくつかのネットワークについて、「素の状態」「cSE」「sSE」「scSE」の 4 パターンで実験しています。\nここでは DenseNet のケースについてまとめた図を論文中の Fig.2 から引用します。\n詳細や全体像は論文を参照してください。\n\n![image.png](https://qiita-image-store.s3.amazonaws.com/0/39030/31a9cee5-5d22-b682-1400-b3f98bfe5ae3.png)\n\n横軸はタスク名です。\nタスクにもよりますが、概ね `DenseNets` < `DenseNets + cSE` < `DenseNets + sSE` < `DenseNets + scSE` になっているように見えます。\ncSE だけをいれると素の状態より性能が悪くなっているケースも見られるのが面白いところです。\n\n## まとめと感想\n\nタスクの特性を見て仮説を立て、実際にそれがうまくハマっているという論文で、よみやすいし納得感のある論文でした。\n実装の容易さと試しやすさ（既存モデルへ着脱できる）がうれしい手法で、実際に活用しているモデルに組み込まれています。\n","slug":"【論文紹介】Concurrent_Spatial_and_Channel_Squeeze_&_Excitation_in_Fully_Convolutional_Networks","title":"【論文紹介】Concurrent Spatial and Channel Squeeze & Excitation in Fully Convolutional Networks","timestamp":1546581067000,"tags":["Python","DeepLearning","Keras","TensorFlow","論文読み"]}]},"__N_SSG":true}