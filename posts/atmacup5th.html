<!DOCTYPE html><html><head><meta name="viewport" content="width=device-width"/><meta charSet="utf-8"/><title>atmaCup #5 に参加してきて Private 29 位（Public 27 位）でした！ | 右上↗</title><meta property="og:type" content="website"/><meta property="og:title" content="atmaCup #5 に参加してきて Private 29 位（Public 27 位）でした！"/><meta property="og:site_name" content="右上↗"/><meta property="twitter:card" content="summary"/><meta property="twitter:creator" content="@agatan_"/><meta property="twitter:title" content="atmaCup #5 に参加してきて Private 29 位（Public 27 位）でした！"/><meta name="next-head-count" content="9"/><link rel="preload" href="/_next/static/css/fcf459cc03a0aa33d72b.css" as="style"/><link rel="stylesheet" href="/_next/static/css/fcf459cc03a0aa33d72b.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-a54b4f32bdc1ef890ddd.js"></script><script src="/_next/static/chunks/webpack-20d43e08bea62467b090.js" defer=""></script><script src="/_next/static/chunks/framework-92300432a1172ef1338b.js" defer=""></script><script src="/_next/static/chunks/main-588261c74baf7142d208.js" defer=""></script><script src="/_next/static/chunks/pages/_app-a9e8b7fcb86503283a43.js" defer=""></script><script src="/_next/static/chunks/1bfc9850-b731c6aa1c491f14d361.js" defer=""></script><script src="/_next/static/chunks/191-ac794077f326adb56e38.js" defer=""></script><script src="/_next/static/chunks/686-4b319bb0411076e06dbc.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bslug%5D-3b1d79cd751fba9fda5d.js" defer=""></script><script src="/_next/static/LTCqLRPEd5Qd2agqEQJZo/_buildManifest.js" defer=""></script><script src="/_next/static/LTCqLRPEd5Qd2agqEQJZo/_ssgManifest.js" defer=""></script></head><body><div id="__next"><style data-emotion="css-global o7558t">:host,:root{--chakra-ring-inset:var(--chakra-empty,/*!*/ /*!*/);--chakra-ring-offset-width:0px;--chakra-ring-offset-color:#fff;--chakra-ring-color:rgba(66, 153, 225, 0.6);--chakra-ring-offset-shadow:0 0 #0000;--chakra-ring-shadow:0 0 #0000;--chakra-space-x-reverse:0;--chakra-space-y-reverse:0;--chakra-colors-transparent:transparent;--chakra-colors-current:currentColor;--chakra-colors-black:#000000;--chakra-colors-white:#FFFFFF;--chakra-colors-whiteAlpha-50:rgba(255, 255, 255, 0.04);--chakra-colors-whiteAlpha-100:rgba(255, 255, 255, 0.06);--chakra-colors-whiteAlpha-200:rgba(255, 255, 255, 0.08);--chakra-colors-whiteAlpha-300:rgba(255, 255, 255, 0.16);--chakra-colors-whiteAlpha-400:rgba(255, 255, 255, 0.24);--chakra-colors-whiteAlpha-500:rgba(255, 255, 255, 0.36);--chakra-colors-whiteAlpha-600:rgba(255, 255, 255, 0.48);--chakra-colors-whiteAlpha-700:rgba(255, 255, 255, 0.64);--chakra-colors-whiteAlpha-800:rgba(255, 255, 255, 0.80);--chakra-colors-whiteAlpha-900:rgba(255, 255, 255, 0.92);--chakra-colors-blackAlpha-50:rgba(0, 0, 0, 0.04);--chakra-colors-blackAlpha-100:rgba(0, 0, 0, 0.06);--chakra-colors-blackAlpha-200:rgba(0, 0, 0, 0.08);--chakra-colors-blackAlpha-300:rgba(0, 0, 0, 0.16);--chakra-colors-blackAlpha-400:rgba(0, 0, 0, 0.24);--chakra-colors-blackAlpha-500:rgba(0, 0, 0, 0.36);--chakra-colors-blackAlpha-600:rgba(0, 0, 0, 0.48);--chakra-colors-blackAlpha-700:rgba(0, 0, 0, 0.64);--chakra-colors-blackAlpha-800:rgba(0, 0, 0, 0.80);--chakra-colors-blackAlpha-900:rgba(0, 0, 0, 0.92);--chakra-colors-gray-50:#F7FAFC;--chakra-colors-gray-100:#EDF2F7;--chakra-colors-gray-200:#E2E8F0;--chakra-colors-gray-300:#CBD5E0;--chakra-colors-gray-400:#A0AEC0;--chakra-colors-gray-500:#718096;--chakra-colors-gray-600:#4A5568;--chakra-colors-gray-700:#2D3748;--chakra-colors-gray-800:#1A202C;--chakra-colors-gray-900:#171923;--chakra-colors-red-50:#FFF5F5;--chakra-colors-red-100:#FED7D7;--chakra-colors-red-200:#FEB2B2;--chakra-colors-red-300:#FC8181;--chakra-colors-red-400:#F56565;--chakra-colors-red-500:#E53E3E;--chakra-colors-red-600:#C53030;--chakra-colors-red-700:#9B2C2C;--chakra-colors-red-800:#822727;--chakra-colors-red-900:#63171B;--chakra-colors-orange-50:#FFFAF0;--chakra-colors-orange-100:#FEEBC8;--chakra-colors-orange-200:#FBD38D;--chakra-colors-orange-300:#F6AD55;--chakra-colors-orange-400:#ED8936;--chakra-colors-orange-500:#DD6B20;--chakra-colors-orange-600:#C05621;--chakra-colors-orange-700:#9C4221;--chakra-colors-orange-800:#7B341E;--chakra-colors-orange-900:#652B19;--chakra-colors-yellow-50:#FFFFF0;--chakra-colors-yellow-100:#FEFCBF;--chakra-colors-yellow-200:#FAF089;--chakra-colors-yellow-300:#F6E05E;--chakra-colors-yellow-400:#ECC94B;--chakra-colors-yellow-500:#D69E2E;--chakra-colors-yellow-600:#B7791F;--chakra-colors-yellow-700:#975A16;--chakra-colors-yellow-800:#744210;--chakra-colors-yellow-900:#5F370E;--chakra-colors-green-50:#F0FFF4;--chakra-colors-green-100:#C6F6D5;--chakra-colors-green-200:#9AE6B4;--chakra-colors-green-300:#68D391;--chakra-colors-green-400:#48BB78;--chakra-colors-green-500:#38A169;--chakra-colors-green-600:#2F855A;--chakra-colors-green-700:#276749;--chakra-colors-green-800:#22543D;--chakra-colors-green-900:#1C4532;--chakra-colors-teal-50:#E6FFFA;--chakra-colors-teal-100:#B2F5EA;--chakra-colors-teal-200:#81E6D9;--chakra-colors-teal-300:#4FD1C5;--chakra-colors-teal-400:#38B2AC;--chakra-colors-teal-500:#319795;--chakra-colors-teal-600:#2C7A7B;--chakra-colors-teal-700:#285E61;--chakra-colors-teal-800:#234E52;--chakra-colors-teal-900:#1D4044;--chakra-colors-blue-50:#ebf8ff;--chakra-colors-blue-100:#bee3f8;--chakra-colors-blue-200:#90cdf4;--chakra-colors-blue-300:#63b3ed;--chakra-colors-blue-400:#4299e1;--chakra-colors-blue-500:#3182ce;--chakra-colors-blue-600:#2b6cb0;--chakra-colors-blue-700:#2c5282;--chakra-colors-blue-800:#2a4365;--chakra-colors-blue-900:#1A365D;--chakra-colors-cyan-50:#EDFDFD;--chakra-colors-cyan-100:#C4F1F9;--chakra-colors-cyan-200:#9DECF9;--chakra-colors-cyan-300:#76E4F7;--chakra-colors-cyan-400:#0BC5EA;--chakra-colors-cyan-500:#00B5D8;--chakra-colors-cyan-600:#00A3C4;--chakra-colors-cyan-700:#0987A0;--chakra-colors-cyan-800:#086F83;--chakra-colors-cyan-900:#065666;--chakra-colors-purple-50:#FAF5FF;--chakra-colors-purple-100:#E9D8FD;--chakra-colors-purple-200:#D6BCFA;--chakra-colors-purple-300:#B794F4;--chakra-colors-purple-400:#9F7AEA;--chakra-colors-purple-500:#805AD5;--chakra-colors-purple-600:#6B46C1;--chakra-colors-purple-700:#553C9A;--chakra-colors-purple-800:#44337A;--chakra-colors-purple-900:#322659;--chakra-colors-pink-50:#FFF5F7;--chakra-colors-pink-100:#FED7E2;--chakra-colors-pink-200:#FBB6CE;--chakra-colors-pink-300:#F687B3;--chakra-colors-pink-400:#ED64A6;--chakra-colors-pink-500:#D53F8C;--chakra-colors-pink-600:#B83280;--chakra-colors-pink-700:#97266D;--chakra-colors-pink-800:#702459;--chakra-colors-pink-900:#521B41;--chakra-colors-linkedin-50:#E8F4F9;--chakra-colors-linkedin-100:#CFEDFB;--chakra-colors-linkedin-200:#9BDAF3;--chakra-colors-linkedin-300:#68C7EC;--chakra-colors-linkedin-400:#34B3E4;--chakra-colors-linkedin-500:#00A0DC;--chakra-colors-linkedin-600:#008CC9;--chakra-colors-linkedin-700:#0077B5;--chakra-colors-linkedin-800:#005E93;--chakra-colors-linkedin-900:#004471;--chakra-colors-facebook-50:#E8F4F9;--chakra-colors-facebook-100:#D9DEE9;--chakra-colors-facebook-200:#B7C2DA;--chakra-colors-facebook-300:#6482C0;--chakra-colors-facebook-400:#4267B2;--chakra-colors-facebook-500:#385898;--chakra-colors-facebook-600:#314E89;--chakra-colors-facebook-700:#29487D;--chakra-colors-facebook-800:#223B67;--chakra-colors-facebook-900:#1E355B;--chakra-colors-messenger-50:#D0E6FF;--chakra-colors-messenger-100:#B9DAFF;--chakra-colors-messenger-200:#A2CDFF;--chakra-colors-messenger-300:#7AB8FF;--chakra-colors-messenger-400:#2E90FF;--chakra-colors-messenger-500:#0078FF;--chakra-colors-messenger-600:#0063D1;--chakra-colors-messenger-700:#0052AC;--chakra-colors-messenger-800:#003C7E;--chakra-colors-messenger-900:#002C5C;--chakra-colors-whatsapp-50:#dffeec;--chakra-colors-whatsapp-100:#b9f5d0;--chakra-colors-whatsapp-200:#90edb3;--chakra-colors-whatsapp-300:#65e495;--chakra-colors-whatsapp-400:#3cdd78;--chakra-colors-whatsapp-500:#22c35e;--chakra-colors-whatsapp-600:#179848;--chakra-colors-whatsapp-700:#0c6c33;--chakra-colors-whatsapp-800:#01421c;--chakra-colors-whatsapp-900:#001803;--chakra-colors-twitter-50:#E5F4FD;--chakra-colors-twitter-100:#C8E9FB;--chakra-colors-twitter-200:#A8DCFA;--chakra-colors-twitter-300:#83CDF7;--chakra-colors-twitter-400:#57BBF5;--chakra-colors-twitter-500:#1DA1F2;--chakra-colors-twitter-600:#1A94DA;--chakra-colors-twitter-700:#1681BF;--chakra-colors-twitter-800:#136B9E;--chakra-colors-twitter-900:#0D4D71;--chakra-colors-telegram-50:#E3F2F9;--chakra-colors-telegram-100:#C5E4F3;--chakra-colors-telegram-200:#A2D4EC;--chakra-colors-telegram-300:#7AC1E4;--chakra-colors-telegram-400:#47A9DA;--chakra-colors-telegram-500:#0088CC;--chakra-colors-telegram-600:#007AB8;--chakra-colors-telegram-700:#006BA1;--chakra-colors-telegram-800:#005885;--chakra-colors-telegram-900:#003F5E;--chakra-borders-none:0;--chakra-borders-1px:1px solid;--chakra-borders-2px:2px solid;--chakra-borders-4px:4px solid;--chakra-borders-8px:8px solid;--chakra-fonts-heading:-apple-system,BlinkMacSystemFont,"Segoe UI",Helvetica,Arial,sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol";--chakra-fonts-body:-apple-system,BlinkMacSystemFont,"Segoe UI",Helvetica,Arial,sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol";--chakra-fonts-mono:SFMono-Regular,Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace;--chakra-fontSizes-xs:0.75rem;--chakra-fontSizes-sm:0.875rem;--chakra-fontSizes-md:1rem;--chakra-fontSizes-lg:1.125rem;--chakra-fontSizes-xl:1.25rem;--chakra-fontSizes-2xl:1.5rem;--chakra-fontSizes-3xl:1.875rem;--chakra-fontSizes-4xl:2.25rem;--chakra-fontSizes-5xl:3rem;--chakra-fontSizes-6xl:3.75rem;--chakra-fontSizes-7xl:4.5rem;--chakra-fontSizes-8xl:6rem;--chakra-fontSizes-9xl:8rem;--chakra-fontWeights-hairline:100;--chakra-fontWeights-thin:200;--chakra-fontWeights-light:300;--chakra-fontWeights-normal:400;--chakra-fontWeights-medium:500;--chakra-fontWeights-semibold:600;--chakra-fontWeights-bold:700;--chakra-fontWeights-extrabold:800;--chakra-fontWeights-black:900;--chakra-letterSpacings-tighter:-0.05em;--chakra-letterSpacings-tight:-0.025em;--chakra-letterSpacings-normal:0;--chakra-letterSpacings-wide:0.025em;--chakra-letterSpacings-wider:0.05em;--chakra-letterSpacings-widest:0.1em;--chakra-lineHeights-3:.75rem;--chakra-lineHeights-4:1rem;--chakra-lineHeights-5:1.25rem;--chakra-lineHeights-6:1.5rem;--chakra-lineHeights-7:1.75rem;--chakra-lineHeights-8:2rem;--chakra-lineHeights-9:2.25rem;--chakra-lineHeights-10:2.5rem;--chakra-lineHeights-normal:normal;--chakra-lineHeights-none:1;--chakra-lineHeights-shorter:1.25;--chakra-lineHeights-short:1.375;--chakra-lineHeights-base:1.5;--chakra-lineHeights-tall:1.625;--chakra-lineHeights-taller:2;--chakra-radii-none:0;--chakra-radii-sm:0.125rem;--chakra-radii-base:0.25rem;--chakra-radii-md:0.375rem;--chakra-radii-lg:0.5rem;--chakra-radii-xl:0.75rem;--chakra-radii-2xl:1rem;--chakra-radii-3xl:1.5rem;--chakra-radii-full:9999px;--chakra-space-1:0.25rem;--chakra-space-2:0.5rem;--chakra-space-3:0.75rem;--chakra-space-4:1rem;--chakra-space-5:1.25rem;--chakra-space-6:1.5rem;--chakra-space-7:1.75rem;--chakra-space-8:2rem;--chakra-space-9:2.25rem;--chakra-space-10:2.5rem;--chakra-space-12:3rem;--chakra-space-14:3.5rem;--chakra-space-16:4rem;--chakra-space-20:5rem;--chakra-space-24:6rem;--chakra-space-28:7rem;--chakra-space-32:8rem;--chakra-space-36:9rem;--chakra-space-40:10rem;--chakra-space-44:11rem;--chakra-space-48:12rem;--chakra-space-52:13rem;--chakra-space-56:14rem;--chakra-space-60:15rem;--chakra-space-64:16rem;--chakra-space-72:18rem;--chakra-space-80:20rem;--chakra-space-96:24rem;--chakra-space-px:1px;--chakra-space-0\.5:0.125rem;--chakra-space-1\.5:0.375rem;--chakra-space-2\.5:0.625rem;--chakra-space-3\.5:0.875rem;--chakra-shadows-xs:0 0 0 1px rgba(0, 0, 0, 0.05);--chakra-shadows-sm:0 1px 2px 0 rgba(0, 0, 0, 0.05);--chakra-shadows-base:0 1px 3px 0 rgba(0, 0, 0, 0.1),0 1px 2px 0 rgba(0, 0, 0, 0.06);--chakra-shadows-md:0 4px 6px -1px rgba(0, 0, 0, 0.1),0 2px 4px -1px rgba(0, 0, 0, 0.06);--chakra-shadows-lg:0 10px 15px -3px rgba(0, 0, 0, 0.1),0 4px 6px -2px rgba(0, 0, 0, 0.05);--chakra-shadows-xl:0 20px 25px -5px rgba(0, 0, 0, 0.1),0 10px 10px -5px rgba(0, 0, 0, 0.04);--chakra-shadows-2xl:0 25px 50px -12px rgba(0, 0, 0, 0.25);--chakra-shadows-outline:0 0 0 3px rgba(66, 153, 225, 0.6);--chakra-shadows-inner:inset 0 2px 4px 0 rgba(0,0,0,0.06);--chakra-shadows-none:none;--chakra-shadows-dark-lg:rgba(0, 0, 0, 0.1) 0px 0px 0px 1px,rgba(0, 0, 0, 0.2) 0px 5px 10px,rgba(0, 0, 0, 0.4) 0px 15px 40px;--chakra-sizes-1:0.25rem;--chakra-sizes-2:0.5rem;--chakra-sizes-3:0.75rem;--chakra-sizes-4:1rem;--chakra-sizes-5:1.25rem;--chakra-sizes-6:1.5rem;--chakra-sizes-7:1.75rem;--chakra-sizes-8:2rem;--chakra-sizes-9:2.25rem;--chakra-sizes-10:2.5rem;--chakra-sizes-12:3rem;--chakra-sizes-14:3.5rem;--chakra-sizes-16:4rem;--chakra-sizes-20:5rem;--chakra-sizes-24:6rem;--chakra-sizes-28:7rem;--chakra-sizes-32:8rem;--chakra-sizes-36:9rem;--chakra-sizes-40:10rem;--chakra-sizes-44:11rem;--chakra-sizes-48:12rem;--chakra-sizes-52:13rem;--chakra-sizes-56:14rem;--chakra-sizes-60:15rem;--chakra-sizes-64:16rem;--chakra-sizes-72:18rem;--chakra-sizes-80:20rem;--chakra-sizes-96:24rem;--chakra-sizes-px:1px;--chakra-sizes-0\.5:0.125rem;--chakra-sizes-1\.5:0.375rem;--chakra-sizes-2\.5:0.625rem;--chakra-sizes-3\.5:0.875rem;--chakra-sizes-max:max-content;--chakra-sizes-min:min-content;--chakra-sizes-full:100%;--chakra-sizes-3xs:14rem;--chakra-sizes-2xs:16rem;--chakra-sizes-xs:20rem;--chakra-sizes-sm:24rem;--chakra-sizes-md:28rem;--chakra-sizes-lg:32rem;--chakra-sizes-xl:36rem;--chakra-sizes-2xl:42rem;--chakra-sizes-3xl:48rem;--chakra-sizes-4xl:56rem;--chakra-sizes-5xl:64rem;--chakra-sizes-6xl:72rem;--chakra-sizes-7xl:80rem;--chakra-sizes-8xl:90rem;--chakra-sizes-container-sm:640px;--chakra-sizes-container-md:768px;--chakra-sizes-container-lg:1024px;--chakra-sizes-container-xl:1280px;--chakra-zIndices-hide:-1;--chakra-zIndices-auto:auto;--chakra-zIndices-base:0;--chakra-zIndices-docked:10;--chakra-zIndices-dropdown:1000;--chakra-zIndices-sticky:1100;--chakra-zIndices-banner:1200;--chakra-zIndices-overlay:1300;--chakra-zIndices-modal:1400;--chakra-zIndices-popover:1500;--chakra-zIndices-skipLink:1600;--chakra-zIndices-toast:1700;--chakra-zIndices-tooltip:1800;--chakra-transition-property-common:background-color,border-color,color,fill,stroke,opacity,box-shadow,transform;--chakra-transition-property-colors:background-color,border-color,color,fill,stroke;--chakra-transition-property-dimensions:width,height;--chakra-transition-property-position:left,right,top,bottom;--chakra-transition-property-background:background-color,background-image,background-position;--chakra-transition-easing-ease-in:cubic-bezier(0.4, 0, 1, 1);--chakra-transition-easing-ease-out:cubic-bezier(0, 0, 0.2, 1);--chakra-transition-easing-ease-in-out:cubic-bezier(0.4, 0, 0.2, 1);--chakra-transition-duration-ultra-fast:50ms;--chakra-transition-duration-faster:100ms;--chakra-transition-duration-fast:150ms;--chakra-transition-duration-normal:200ms;--chakra-transition-duration-slow:300ms;--chakra-transition-duration-slower:400ms;--chakra-transition-duration-ultra-slow:500ms;--chakra-blur-none:0;--chakra-blur-sm:4px;--chakra-blur-base:8px;--chakra-blur-md:12px;--chakra-blur-lg:16px;--chakra-blur-xl:24px;--chakra-blur-2xl:40px;--chakra-blur-3xl:64px;}</style><style data-emotion="css-global 1syi0wy">html{line-height:1.5;-webkit-text-size-adjust:100%;font-family:system-ui,sans-serif;-webkit-font-smoothing:antialiased;text-rendering:optimizeLegibility;-moz-osx-font-smoothing:grayscale;touch-action:manipulation;}body{position:relative;min-height:100%;font-feature-settings:'kern';}*,*::before,*::after{border-width:0;border-style:solid;box-sizing:border-box;}main{display:block;}hr{border-top-width:1px;box-sizing:content-box;height:0;overflow:visible;}pre,code,kbd,samp{font-family:SFMono-Regular,Menlo,Monaco,Consolas,monospace;font-size:1em;}a{background-color:transparent;color:inherit;-webkit-text-decoration:inherit;text-decoration:inherit;}abbr[title]{border-bottom:none;-webkit-text-decoration:underline;text-decoration:underline;-webkit-text-decoration:underline dotted;-webkit-text-decoration:underline dotted;text-decoration:underline dotted;}b,strong{font-weight:bold;}small{font-size:80%;}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline;}sub{bottom:-0.25em;}sup{top:-0.5em;}img{border-style:none;}button,input,optgroup,select,textarea{font-family:inherit;font-size:100%;line-height:1.15;margin:0;}button,input{overflow:visible;}button,select{text-transform:none;}button::-moz-focus-inner,[type="button"]::-moz-focus-inner,[type="reset"]::-moz-focus-inner,[type="submit"]::-moz-focus-inner{border-style:none;padding:0;}fieldset{padding:0.35em 0.75em 0.625em;}legend{box-sizing:border-box;color:inherit;display:table;max-width:100%;padding:0;white-space:normal;}progress{vertical-align:baseline;}textarea{overflow:auto;}[type="checkbox"],[type="radio"]{box-sizing:border-box;padding:0;}[type="number"]::-webkit-inner-spin-button,[type="number"]::-webkit-outer-spin-button{-webkit-appearance:none!important;}input[type="number"]{-moz-appearance:textfield;}[type="search"]{-webkit-appearance:textfield;outline-offset:-2px;}[type="search"]::-webkit-search-decoration{-webkit-appearance:none!important;}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit;}details{display:block;}summary{display:-webkit-box;display:-webkit-list-item;display:-ms-list-itembox;display:list-item;}template{display:none;}[hidden]{display:none!important;}body,blockquote,dl,dd,h1,h2,h3,h4,h5,h6,hr,figure,p,pre{margin:0;}button{background:transparent;padding:0;}fieldset{margin:0;padding:0;}ol,ul{margin:0;padding:0;}textarea{resize:vertical;}button,[role="button"]{cursor:pointer;}button::-moz-focus-inner{border:0!important;}table{border-collapse:collapse;}h1,h2,h3,h4,h5,h6{font-size:inherit;font-weight:inherit;}button,input,optgroup,select,textarea{padding:0;line-height:inherit;color:inherit;}img,svg,video,canvas,audio,iframe,embed,object{display:block;vertical-align:middle;}img,video{max-width:100%;height:auto;}[data-js-focus-visible] :focus:not([data-focus-visible-added]){outline:none;box-shadow:none;}select::-ms-expand{display:none;}</style><style data-emotion="css-global 1baqkrf">body{font-family:var(--chakra-fonts-body);color:var(--chakra-colors-gray-800);background:var(--chakra-colors-white);transition-property:background-color;transition-duration:var(--chakra-transition-duration-normal);line-height:var(--chakra-lineHeights-base);}*::-webkit-input-placeholder{color:var(--chakra-colors-gray-400);}*::-moz-placeholder{color:var(--chakra-colors-gray-400);}*:-ms-input-placeholder{color:var(--chakra-colors-gray-400);}*::placeholder{color:var(--chakra-colors-gray-400);}*,*::before,::after{border-color:var(--chakra-colors-gray-200);word-wrap:break-word;}</style><style data-emotion="css d4xd0d">.css-d4xd0d{background-color:var(--chakra-colors-green-50);min-height:100vh;}</style><div class="css-d4xd0d"><style data-emotion="css 50jqoj">.css-50jqoj{width:100%;-webkit-margin-start:auto;margin-inline-start:auto;-webkit-margin-end:auto;margin-inline-end:auto;max-width:var(--chakra-sizes-container-lg);-webkit-padding-start:1rem;padding-inline-start:1rem;-webkit-padding-end:1rem;padding-inline-end:1rem;background-color:var(--chakra-colors-green-600);}</style><div class="chakra-container css-50jqoj"><style data-emotion="css jbx4q3">.css-jbx4q3{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:flex-end;-webkit-box-align:flex-end;-ms-flex-align:flex-end;align-items:flex-end;padding:var(--chakra-space-8);}</style><div class="css-jbx4q3"><style data-emotion="css 1dklj6k">.css-1dklj6k{font-family:var(--chakra-fonts-heading);font-weight:var(--chakra-fontWeights-bold);font-size:var(--chakra-fontSizes-3xl);line-height:1.33;}@media screen and (min-width: 48em){.css-1dklj6k{font-size:var(--chakra-fontSizes-4xl);line-height:1.2;}}</style><h2 class="chakra-heading css-1dklj6k"><style data-emotion="css 1naxmyz">.css-1naxmyz{transition-property:var(--chakra-transition-property-common);transition-duration:var(--chakra-transition-duration-fast);transition-timing-function:var(--chakra-transition-easing-ease-out);cursor:pointer;-webkit-text-decoration:none;text-decoration:none;outline:2px solid transparent;outline-offset:2px;color:var(--chakra-colors-white);}.css-1naxmyz:hover,.css-1naxmyz[data-hover]{-webkit-text-decoration:underline;text-decoration:underline;}.css-1naxmyz:focus,.css-1naxmyz[data-focus]{box-shadow:var(--chakra-shadows-outline);}</style><a class="chakra-link css-1naxmyz" href="/"><u class="chakra-text css-0">↗ agatan blog ↗</u></a></h2><style data-emotion="css 17xejub">.css-17xejub{-webkit-flex:1;-ms-flex:1;flex:1;justify-self:stretch;-webkit-align-self:stretch;-ms-flex-item-align:stretch;align-self:stretch;}</style><div class="css-17xejub"></div><div class="css-0"><style data-emotion="css 1awjy5h">.css-1awjy5h{transition-property:var(--chakra-transition-property-common);transition-duration:var(--chakra-transition-duration-fast);transition-timing-function:var(--chakra-transition-easing-ease-out);cursor:pointer;-webkit-text-decoration:none;text-decoration:none;outline:2px solid transparent;outline-offset:2px;color:inherit;padding:var(--chakra-space-2);}.css-1awjy5h:hover,.css-1awjy5h[data-hover]{-webkit-text-decoration:underline;text-decoration:underline;}.css-1awjy5h:focus,.css-1awjy5h[data-focus]{box-shadow:var(--chakra-shadows-outline);}</style><a class="chakra-link css-1awjy5h" href="/feed.xml"><style data-emotion="css sjogs4">.css-sjogs4{width:var(--chakra-sizes-6);height:var(--chakra-sizes-6);display:inline-block;line-height:1em;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;color:var(--chakra-colors-white);}</style><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" focusable="false" class="chakra-icon css-sjogs4" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M128.081 415.959c0 35.369-28.672 64.041-64.041 64.041S0 451.328 0 415.959s28.672-64.041 64.041-64.041 64.04 28.673 64.04 64.041zm175.66 47.25c-8.354-154.6-132.185-278.587-286.95-286.95C7.656 175.765 0 183.105 0 192.253v48.069c0 8.415 6.49 15.472 14.887 16.018 111.832 7.284 201.473 96.702 208.772 208.772.547 8.397 7.604 14.887 16.018 14.887h48.069c9.149.001 16.489-7.655 15.995-16.79zm144.249.288C439.596 229.677 251.465 40.445 16.503 32.01 7.473 31.686 0 38.981 0 48.016v48.068c0 8.625 6.835 15.645 15.453 15.999 191.179 7.839 344.627 161.316 352.465 352.465.353 8.618 7.373 15.453 15.999 15.453h48.068c9.034-.001 16.329-7.474 16.005-16.504z"></path></svg></a><a class="chakra-link css-1awjy5h" href="/tags"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 640 512" focusable="false" class="chakra-icon css-sjogs4" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M497.941 225.941L286.059 14.059A48 48 0 0 0 252.118 0H48C21.49 0 0 21.49 0 48v204.118a48 48 0 0 0 14.059 33.941l211.882 211.882c18.744 18.745 49.136 18.746 67.882 0l204.118-204.118c18.745-18.745 18.745-49.137 0-67.882zM112 160c-26.51 0-48-21.49-48-48s21.49-48 48-48 48 21.49 48 48-21.49 48-48 48zm513.941 133.823L421.823 497.941c-18.745 18.745-49.137 18.745-67.882 0l-.36-.36L527.64 323.522c16.999-16.999 26.36-39.6 26.36-63.64s-9.362-46.641-26.36-63.64L331.397 0h48.721a48 48 0 0 1 33.941 14.059l211.882 211.882c18.745 18.745 18.745 49.137 0 67.882z"></path></svg></a></div></div></div><style data-emotion="css 8shb6n">.css-8shb6n{width:100%;-webkit-margin-start:auto;margin-inline-start:auto;-webkit-margin-end:auto;margin-inline-end:auto;max-width:var(--chakra-sizes-container-lg);-webkit-padding-start:1rem;padding-inline-start:1rem;-webkit-padding-end:1rem;padding-inline-end:1rem;background-color:var(--chakra-colors-white);min-height:100vh;}</style><div class="chakra-container css-8shb6n"><style data-emotion="css 10qlibn">.css-10qlibn{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;padding-top:var(--chakra-space-4);padding-bottom:var(--chakra-space-4);}</style><div class="css-10qlibn"><style data-emotion="css 8jfdow">.css-8jfdow{width:100%;-webkit-margin-start:auto;margin-inline-start:auto;-webkit-margin-end:auto;margin-inline-end:auto;max-width:var(--chakra-sizes-container-lg);-webkit-padding-start:1rem;padding-inline-start:1rem;-webkit-padding-end:1rem;padding-inline-end:1rem;padding:0px;margin:0px;}</style><div class="chakra-container css-8jfdow"><style data-emotion="css nm5t63">.css-nm5t63{width:100%;-webkit-margin-start:auto;margin-inline-start:auto;-webkit-margin-end:auto;margin-inline-end:auto;max-width:var(--chakra-sizes-container-md);-webkit-padding-start:1rem;padding-inline-start:1rem;-webkit-padding-end:1rem;padding-inline-end:1rem;}</style><div class="chakra-container css-nm5t63"><style data-emotion="css 6euoq0">.css-6euoq0{font-family:var(--chakra-fonts-heading);font-weight:var(--chakra-fontWeights-bold);font-size:var(--chakra-fontSizes-3xl);line-height:1.33;padding-bottom:var(--chakra-space-4);}@media screen and (min-width: 48em){.css-6euoq0{line-height:1.2;}}</style><h2 class="chakra-heading css-6euoq0">atmaCup #5 に参加してきて Private 29 位（Public 27 位）でした！</h2><style data-emotion="css 8zn9ea">.css-8zn9ea{opacity:0.6;border:0;border-color:inherit;border-style:solid;border-bottom-width:1px;width:100%;padding:var(--chakra-space-2);}</style><hr aria-orientation="horizontal" class="chakra-divider css-8zn9ea"/><style data-emotion="css 1rwovhe">.css-1rwovhe{padding-top:var(--chakra-space-4);}</style><div class="css-1rwovhe"><div><style data-emotion="css ykzoaw">.css-ykzoaw{font-size:medium;line-height:var(--chakra-lineHeights-7);padding:var(--chakra-space-1);}</style><p class="chakra-text css-ykzoaw">atmaCup #5 に参加してきました！
<iframe src="https://hatenablog-parts.com/embed?url=https%3A%2F%2Fatma.connpass.com%2Fevent%2F175139%2F" title="【おうちで】atmaCup オンサイトデータコンペ#5 (2020/05/29 18:00〜)" class="embed-card embed-webcard" scrolling="no" frameBorder="0" style="display:block;width:100%;height:155px;max-width:500px;margin:10px 0px"></iframe><cite class="hatena-citation"><style data-emotion="css f4h6uy">.css-f4h6uy{transition-property:var(--chakra-transition-property-common);transition-duration:var(--chakra-transition-duration-fast);transition-timing-function:var(--chakra-transition-easing-ease-out);cursor:pointer;-webkit-text-decoration:none;text-decoration:none;outline:2px solid transparent;outline-offset:2px;color:inherit;}.css-f4h6uy:hover,.css-f4h6uy[data-hover]{-webkit-text-decoration:underline;text-decoration:underline;}.css-f4h6uy:focus,.css-f4h6uy[data-focus]{box-shadow:var(--chakra-shadows-outline);}</style><a class="chakra-link css-f4h6uy" href="https://atma.connpass.com/event/175139/"><style data-emotion="css hn1ydt">.css-hn1ydt{color:var(--chakra-colors-green-600);}</style><span class="chakra-text css-hn1ydt">atma.connpass.com</span></a></cite></p>
<p class="chakra-text css-ykzoaw">Kaggle 以外のコンペに参加したのは初めてだったのですが、お祭り感があってとても楽しかったです！
参加者・運営全体で盛り上げていく雰囲気があったので、初参加でしたが最後までモチベーション高く取り組み続けることができました。
<a class="chakra-link css-f4h6uy" href="http://d.hatena.ne.jp/keyword/Twitter"><span class="chakra-text css-hn1ydt">Twitter</span></a> TL でよく見かける方々と競えるので燃えました。</p>
<p class="chakra-text css-ykzoaw">運営のみなさま、本当にありがとうございました！ぜひまた参加したいです！</p>
<style data-emotion="css 1m5epeg">.css-1m5epeg{font-family:var(--chakra-fonts-heading);font-weight:var(--chakra-fontWeights-bold);font-size:large;line-height:1.33;padding-top:var(--chakra-space-2);padding-bottom:var(--chakra-space-2);}@media screen and (min-width: 48em){.css-1m5epeg{line-height:1.2;}}</style><h2 class="chakra-heading css-1m5epeg" id="問題設定"><style data-emotion="css 70qvj9">.css-70qvj9{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}</style><div class="css-70qvj9"><a class="chakra-link css-1awjy5h" href="#問題設定"><style data-emotion="css ifa7ya">.css-ifa7ya{width:var(--chakra-sizes-4);height:var(--chakra-sizes-4);display:inline-block;line-height:1em;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;color:var(--chakra-colors-gray-500);}</style><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" focusable="false" class="chakra-icon css-ifa7ya" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>問題設定</div></h2>
<p class="chakra-text css-ykzoaw">2 値分類タスクで、評価指標は PR-AUC でした。
正例が少なく、指標も PR-AUC だったので、CV / LB が安定しなかったのが悩ましいところでした。</p>
<h2 class="chakra-heading css-1m5epeg" id="コンペ中の動き"><div class="css-70qvj9"><a class="chakra-link css-1awjy5h" href="#コンペ中の動き"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" focusable="false" class="chakra-icon css-ifa7ya" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>コンペ中の動き</div></h2>
<p class="chakra-text css-ykzoaw">1 週間の開催で短期決戦だったので、<a class="chakra-link css-f4h6uy" href="http://d.hatena.ne.jp/keyword/%A5%C9%A5%E1%A5%A4%A5%F3"><span class="chakra-text css-hn1ydt">ドメイン</span></a>知識の獲得から始める余裕はないと判断して、CNN 様に抽出していただく戦略を取りました。（結果的にそこそこ NN チューニングに時間を使ったので、<a class="chakra-link css-f4h6uy" href="http://d.hatena.ne.jp/keyword/%A5%C9%A5%E1%A5%A4%A5%F3"><span class="chakra-text css-hn1ydt">ドメイン</span></a>知識をちゃんと学びに行けばよかったとやや後悔しています）
また、短期決戦前提の書き殴り実験をしまくってしまったので、自分が何をやっていたのか正確な記録が無く終盤若干混乱しました。1 週間だったのでギリギリなんとかなりましたが、Kaggle みたいな長期戦は厳しそうなので、そっちに挑む際はもうちょっと丁寧に生きた方が良さそう。仮に入賞したとしても再現できるようにするコストがものすごく高い実装になってしまっていました...</p>
<p class="chakra-text css-ykzoaw">実験管理を mlflow でやったのですが、結構よかったです。
最終日はローカルを投げ捨てて <a class="chakra-link css-f4h6uy" href="http://d.hatena.ne.jp/keyword/GPU"><span class="chakra-text css-hn1ydt">GPU</span></a> 使い始めたので、今までローカルに積み上げてきた実験との比較が若干厄介でした。（統合せず、別の <code>mlflow ui</code> をタブで開いて眺めていました...）
ただ、CV 戦略を変えたり評価指標をいじったときに、同条件で単純比較できない実験にもかかわらずそれが同じテーブルに並んでしまうのが悩ましいなと思いました。
時系列で並んでいるうちは良いのですが、指標ごとにソートすると本当にどれが信じられる結果なのかわかり辛くなってしまいました。
このあたりはタグなどを活用すると良いのかもしれない？もしくは CV などの設計が変わった時点できちんと experiment のレベルで分離すべきだった気がします。</p>
<p class="chakra-text css-ykzoaw">また、実は事前にちょこっとだけ準備していて、「学習データ、テストデータ、CV、モデル、評価関数」あたりを渡すと mlflow にログを書きつつ CV 評価して oof と test の prediction をはく薄い wrapper を書いていました。
最初はまぁ使えていたんですが、NN のことを全く想定していなかったので NN に移った時点で全く使えなくなってしまったのと、細かいことをやりだすとやっぱり wrap された内部に手を入れたくなってしまって厳しかったです。
予想はしていたので相当薄めに作ったつもりだったのですが、それでもこうなっちゃうか〜という感じでちょっと辛い。
ライブラリとしての作りにしたのが間違いだったのかもと思っています。ライブラリだと内部にコンペ固有の変更を入れるのは厳しいので。
単なる<a class="chakra-link css-f4h6uy" href="http://d.hatena.ne.jp/keyword/%A5%B9%A5%CB%A5%DA%A5%C3%A5%C8"><span class="chakra-text css-hn1ydt">スニペット</span></a>集にしておいて、コンペ中はゴリゴリ内部も書き換える前提で使った方が良さそう。</p>
<h2 class="chakra-heading css-1m5epeg" id="やったこと"><div class="css-70qvj9"><a class="chakra-link css-1awjy5h" href="#やったこと"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" focusable="false" class="chakra-icon css-ifa7ya" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>やったこと</div></h2>
<p class="chakra-text css-ykzoaw">以下は Discussion にも投稿した内容とほぼ同じですが、こちらにも書いておきます。</p>
<p class="chakra-text css-ykzoaw"><a class="chakra-link css-f4h6uy" href="https://guruguru.ml/competitions/10/discussions/34d99be1-ab52-4868-a46c-45a24fac8308/"><span class="chakra-text css-hn1ydt">ぐるぐる</span></a></p>
<p class="chakra-text css-ykzoaw">中盤まで CV スコアすら安定せず、ちょっとシードを変えるだけで大きくスコアが変動してしまっていました。
そのため、正直何が効いていて何が効かなかったのかの判断を誤っていた可能性が高いです...</p>
<p class="chakra-text css-ykzoaw">何をやっても安定しなかったので、最終盤にやけになってアンサンブルで誤魔化す作戦に出たのですが、これは結果的によかったと思います。
特に、CV がある程度安定して比較可能になったおかげで、打つべき手の選択を見誤り辛くなったのが大きかったです。
逆にいえばもっと早くこれをやっておけば、もう少し良いモデルを作れたかも？と反省しています。次回に活かしたいです。</p>
<p class="chakra-text css-ykzoaw">最終サブは CNN と、それをベースに stacking した LightGBM の 2 つを出していました。</p>
<h2 class="chakra-heading css-1m5epeg" id="cnn"><div class="css-70qvj9"><a class="chakra-link css-1awjy5h" href="#cnn"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" focusable="false" class="chakra-icon css-ifa7ya" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>CNN</div></h2>
<style data-emotion="css 1h3xlp0">.css-1h3xlp0{list-style-type:initial;-webkit-margin-start:1em;margin-inline-start:1em;padding-left:var(--chakra-space-4);}</style><ul role="list" class="css-1h3xlp0"><li class="css-0">正規化 / Scaling を全くせずナイーブに Conv1D ベースの NN に突っ込む
<ul role="list" class="css-1h3xlp0"><li class="css-0"><code>((Skip Connection + Conv1D (kernel_size=5) → BatchNorm (or GroupNorm) → ReLU) * 2 → AveragePooling1D (pool_size=2, strides=2)) * 3 → GlobalAveragePooling と GlobalMaxPooling の concat</code></li></ul>
</li><li class="css-0">テーブル特徴量は <a class="chakra-link css-f4h6uy" href="http://d.hatena.ne.jp/keyword/MLP"><span class="chakra-text css-hn1ydt">MLP</span></a> を通して CNN の出力に Concatenate した
<ul role="list" class="css-1h3xlp0"><li class="css-0">採用した特徴量は beta, <a class="chakra-link css-f4h6uy" href="http://d.hatena.ne.jp/keyword/rms"><span class="chakra-text css-hn1ydt">rms</span></a>, params1 ~ 6, tsfresh の特徴量たちの中から LightGBM での feature importance が上位 100 以内だったものを取ってきただけ</li></ul>
</li><li class="css-0">テーブル特徴量を <a class="chakra-link css-f4h6uy" href="http://d.hatena.ne.jp/keyword/MLP"><span class="chakra-text css-hn1ydt">MLP</span></a> に通したものを CNN の途中でに足したらなぜかスコアが上がったので採用
<ul role="list" class="css-1h3xlp0"><li class="css-0">本当はテーブル特徴量を使って、どの領域に注目するかの Attention の計算をしようと思っていたが、そちらはスコアが上がらず...</li><li class="css-0">悔しいので惰性で試した加算がなぜか効いた</li></ul>
</li><li class="css-0">始めは BN を使っていたが安定しなかった。極端に大きい入力が入ってきたときに BN の statistics がぶっ飛ぶのが悪いのでは、とあたりをつけて GN に変更したところ、伸びはしなかったが安定性が増したように見えたので採用。</li><li class="css-0">Optimizer は AdamW を使っていたが安定しなかったので、SWA / Lookahead を試したところどちらも安定性の向上を確認できた。最終性能はほぼ変わらなかったが、Lookahead の方が収束が速かったのと個人的に好きだったので採用。
<ul role="list" class="css-1h3xlp0"><li class="css-0">Lookahead 採用後は BN でも安定したので、最終的には BN / GN 両方のモデルを作って rank average した。</li><li class="css-0">&amp; CosineDecay with linear warmup</li><li class="css-0">val prauc で early stopping</li></ul>
</li><li class="css-0">学習中に checkpoint をとっておき、val loss がよかった 5 epoch 分のモデルの出力の平均を使用</li><li class="css-0">class weight つき binary crossentropy loss
<ul role="list" class="css-1h3xlp0"><li class="css-0">class imbalance については <a class="chakra-link css-f4h6uy" href="https://www.tensorflow.org/tutorials/structured_data/imbalanced_data#train_on_the_oversampled_data"><span class="chakra-text css-hn1ydt">https://www.tensorflow.org/tutorials/structured_data/imbalanced_data#train_on_the_oversampled_data</span></a> をベースに戦略を立てていました</li><li class="css-0">いくつか試しましたが、結局シンプルな class weight が一番よかったです</li></ul>
</li><li class="css-0">CV 戦略は StratifiedKFold(k=5)
<ul role="list" class="css-1h3xlp0"><li class="css-0">タスク的には StratifiedKFold じゃまずそうと思いつつも、Group, StratifiedGroup は CV / LB の相関が取れなかったのと、seed を変えた時の暴れ方がすごくて断念</li></ul>
</li></ul>
<h2 class="chakra-heading css-1m5epeg" id="lightgbm"><div class="css-70qvj9"><a class="chakra-link css-1awjy5h" href="#lightgbm"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" focusable="false" class="chakra-icon css-ifa7ya" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>LightGBM</div></h2>
<p class="chakra-text css-ykzoaw">こちらは最終日にもう何も思い付かず、とはいえサブを余らせて終わるのも悔しかったので、やってみるかぁという惰性で挑戦したものでした。
CV は Stacking した LightGBM の方がかなり高かったので興奮したのですが、流石に怖かったので CNN も提出していました。
結論としてはどちらも  Public / Private 共にほぼ差はなかったです。</p>
<p class="chakra-text css-ykzoaw">時間がなかったのであまり検証はできず、勘で良さそうな構成を選ぶしかなかったのですが、最終的に採用したのは以下のような構成です。</p>
<ul role="list" class="css-1h3xlp0"><li class="css-0">CNN (BN, GN) の出力を rank にしたもの + テーブル特徴量全部盛り</li><li class="css-0">optuna の LightGBMCVTuner でハイパラ選択</li><li class="css-0">2 Seed Average (Rank Average)</li><li class="css-0">imbalance 対策は undersampling + bagging
<ul role="list" class="css-1h3xlp0"><li class="css-0">1 : 10 になるように undersampling したデータで普通に 20 モデル作り、単純に平均をとった</li><li class="css-0">1:1 にしたり <code>is_unbalance=True</code> にしたりいくつか実験しましたが、これがもっとも CV が高かったです</li></ul>
</li></ul>
<h2 class="chakra-heading css-1m5epeg" id="うまくいかなかったこと"><div class="css-70qvj9"><a class="chakra-link css-1awjy5h" href="#うまくいかなかったこと"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" focusable="false" class="chakra-icon css-ifa7ya" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>うまくいかなかったこと</div></h2>
<ul role="list" class="css-1h3xlp0"><li class="css-0">Attention
<ul role="list" class="css-1h3xlp0"><li class="css-0">Transformer ベースのモデルと、Conv ベースモデルに MultiHeadAttention を足したものの両方を試しましたが、どちらも work せず</li></ul>
</li><li class="css-0">Squeeze and Excitation</li><li class="css-0">SeparableConv1D にして層を増やす</li><li class="css-0">Kernel Size を増やす</li><li class="css-0">NN で Undersampling + Bagging</li><li class="css-0">生データの scaling
<ul role="list" class="css-1h3xlp0"><li class="css-0">Standardize や 99.9%ile で clip した方が学習は安定したが、スコアがものすごく下がった...</li></ul>
</li><li class="css-0">(Denoising) Variational Auto Encoder
<ul role="list" class="css-1h3xlp0"><li class="css-0">train/test で chip が違うことがわかっていたので、教師なし事前学習 → <a class="chakra-link css-f4h6uy" href="http://d.hatena.ne.jp/keyword/finetune"><span class="chakra-text css-hn1ydt">finetune</span></a> したら LB 上がるのでは、という目論見</li><li class="css-0">Reconstruction Error と Encoder の出力 64 次元ベクトルを LightGBM に食わせるのも試したが work せず</li></ul>
</li><li class="css-0"><a class="chakra-link css-f4h6uy" href="http://d.hatena.ne.jp/keyword/%C8%F9%CA%AC"><span class="chakra-text css-hn1ydt">微分</span></a>して入力チャネルに追加して CNN に通す</li></ul>
<hr/>
<hr/>
</div></div><hr aria-orientation="horizontal" class="chakra-divider css-8zn9ea"/><style data-emotion="css 1fgm4wo">.css-1fgm4wo{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;padding-top:var(--chakra-space-2);}</style><div class="css-1fgm4wo"><div class="css-17xejub"></div><style data-emotion="css rjrdo">.css-rjrdo{transition-property:var(--chakra-transition-property-common);transition-duration:var(--chakra-transition-duration-fast);transition-timing-function:var(--chakra-transition-easing-ease-out);cursor:pointer;-webkit-text-decoration:none;text-decoration:none;outline:2px solid transparent;outline-offset:2px;color:var(--chakra-colors-green-500);}.css-rjrdo:hover,.css-rjrdo[data-hover]{-webkit-text-decoration:underline;text-decoration:underline;}.css-rjrdo:focus,.css-rjrdo[data-focus]{box-shadow:var(--chakra-shadows-outline);}</style><a class="chakra-link css-rjrdo" href="https://github.com/agatan/agatan.github.io/blob/main/posts/atmacup5th.md"><style data-emotion="css 6ey7w3">.css-6ey7w3{width:var(--chakra-sizes-6);height:var(--chakra-sizes-6);display:inline-block;line-height:1em;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;color:currentColor;}</style><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" focusable="false" class="chakra-icon css-6ey7w3" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg><style data-emotion="css 1syq16t">.css-1syq16t{padding:var(--chakra-space-2);}</style><span class="chakra-text css-1syq16t">GitHub で編集リクエスト</span></a></div></div></div><style data-emotion="css ul4ode">.css-ul4ode{width:100%;-webkit-margin-start:auto;margin-inline-start:auto;-webkit-margin-end:auto;margin-inline-end:auto;max-width:var(--chakra-sizes-44);-webkit-padding-start:1rem;padding-inline-start:1rem;-webkit-padding-end:1rem;padding-inline-end:1rem;}</style><div class="chakra-container css-ul4ode"><style data-emotion="css xkvmla">.css-xkvmla{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;padding:var(--chakra-space-4);}</style><div class="css-xkvmla"><a class="chakra-link css-f4h6uy" href="https://twitter.com/@agatan_"><style data-emotion="css 1piy145">.css-1piy145{position:relative;width:var(--chakra-sizes-20);height:var(--chakra-sizes-20);}</style><div class="css-1piy145"><style data-emotion="css 1phd9a0">.css-1phd9a0{object-fit:cover;}</style><img alt="agatan" class="chakra-image__placeholder css-1phd9a0" layout="fill"/></div><style data-emotion="css 19dx7hn">.css-19dx7hn{text-align:center;font-size:large;}</style><p class="chakra-text css-19dx7hn">@agatan</p></a><style data-emotion="css 84zodg">.css-84zodg{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;}.css-84zodg>*:not(style)~*:not(style){margin-top:0px;-webkit-margin-end:0px;margin-inline-end:0px;margin-bottom:0px;-webkit-margin-start:0.5rem;margin-inline-start:0.5rem;}</style><div class="chakra-stack css-84zodg"><style data-emotion="css 1h1f62l">.css-1h1f62l{transition-property:var(--chakra-transition-property-common);transition-duration:var(--chakra-transition-duration-fast);transition-timing-function:var(--chakra-transition-easing-ease-out);cursor:pointer;-webkit-text-decoration:none;text-decoration:none;outline:2px solid transparent;outline-offset:2px;color:inherit;padding:var(--chakra-space-1);}.css-1h1f62l:hover,.css-1h1f62l[data-hover]{-webkit-text-decoration:underline;text-decoration:underline;}.css-1h1f62l:focus,.css-1h1f62l[data-focus]{box-shadow:var(--chakra-shadows-outline);}</style><a class="chakra-link css-1h1f62l" href="https://twitter.com/@agatan_"><style data-emotion="css 15e9ude">.css-15e9ude{width:1.2em;height:1.2em;display:inline-block;line-height:1em;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;color:currentColor;}</style><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" focusable="true" class="chakra-icon css-15e9ude" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"></path></svg></a><a class="chakra-link css-1h1f62l" href="https://github.com/agatan"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" focusable="true" class="chakra-icon css-15e9ude" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a></div></div></div></div></div></div><span></span></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"content":"\u003cp\u003eatmaCup #5 に参加してきました！\n\u003ciframe src=\"https://hatenablog-parts.com/embed?url=https%3A%2F%2Fatma.connpass.com%2Fevent%2F175139%2F\" title=\"【おうちで】atmaCup オンサイトデータコンペ#5 (2020/05/29 18:00〜)\" class=\"embed-card embed-webcard\" scrolling=\"no\" frameborder=\"0\" style=\"display: block; width: 100%; height: 155px; max-width: 500px; margin: 10px 0px;\"\u003e\u003c/iframe\u003e\u003ccite class=\"hatena-citation\"\u003e\u003ca href=\"https://atma.connpass.com/event/175139/\"\u003eatma.connpass.com\u003c/a\u003e\u003c/cite\u003e\u003c/p\u003e\n\u003cp\u003eKaggle 以外のコンペに参加したのは初めてだったのですが、お祭り感があってとても楽しかったです！\n参加者・運営全体で盛り上げていく雰囲気があったので、初参加でしたが最後までモチベーション高く取り組み続けることができました。\n\u003ca class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/Twitter\"\u003eTwitter\u003c/a\u003e TL でよく見かける方々と競えるので燃えました。\u003c/p\u003e\n\u003cp\u003e運営のみなさま、本当にありがとうございました！ぜひまた参加したいです！\u003c/p\u003e\n\u003ch3\u003e問題設定\u003c/h3\u003e\n\u003cp\u003e2 値分類タスクで、評価指標は PR-AUC でした。\n正例が少なく、指標も PR-AUC だったので、CV / LB が安定しなかったのが悩ましいところでした。\u003c/p\u003e\n\u003ch3\u003eコンペ中の動き\u003c/h3\u003e\n\u003cp\u003e1 週間の開催で短期決戦だったので、\u003ca class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%C9%A5%E1%A5%A4%A5%F3\"\u003eドメイン\u003c/a\u003e知識の獲得から始める余裕はないと判断して、CNN 様に抽出していただく戦略を取りました。（結果的にそこそこ NN チューニングに時間を使ったので、\u003ca class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%C9%A5%E1%A5%A4%A5%F3\"\u003eドメイン\u003c/a\u003e知識をちゃんと学びに行けばよかったとやや後悔しています）\nまた、短期決戦前提の書き殴り実験をしまくってしまったので、自分が何をやっていたのか正確な記録が無く終盤若干混乱しました。1 週間だったのでギリギリなんとかなりましたが、Kaggle みたいな長期戦は厳しそうなので、そっちに挑む際はもうちょっと丁寧に生きた方が良さそう。仮に入賞したとしても再現できるようにするコストがものすごく高い実装になってしまっていました...\u003c/p\u003e\n\u003cp\u003e実験管理を mlflow でやったのですが、結構よかったです。\n最終日はローカルを投げ捨てて \u003ca class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/GPU\"\u003eGPU\u003c/a\u003e 使い始めたので、今までローカルに積み上げてきた実験との比較が若干厄介でした。（統合せず、別の \u003ccode\u003emlflow ui\u003c/code\u003e をタブで開いて眺めていました...）\nただ、CV 戦略を変えたり評価指標をいじったときに、同条件で単純比較できない実験にもかかわらずそれが同じテーブルに並んでしまうのが悩ましいなと思いました。\n時系列で並んでいるうちは良いのですが、指標ごとにソートすると本当にどれが信じられる結果なのかわかり辛くなってしまいました。\nこのあたりはタグなどを活用すると良いのかもしれない？もしくは CV などの設計が変わった時点できちんと experiment のレベルで分離すべきだった気がします。\u003c/p\u003e\n\u003cp\u003eまた、実は事前にちょこっとだけ準備していて、「学習データ、テストデータ、CV、モデル、評価関数」あたりを渡すと mlflow にログを書きつつ CV 評価して oof と test の prediction をはく薄い wrapper を書いていました。\n最初はまぁ使えていたんですが、NN のことを全く想定していなかったので NN に移った時点で全く使えなくなってしまったのと、細かいことをやりだすとやっぱり wrap された内部に手を入れたくなってしまって厳しかったです。\n予想はしていたので相当薄めに作ったつもりだったのですが、それでもこうなっちゃうか〜という感じでちょっと辛い。\nライブラリとしての作りにしたのが間違いだったのかもと思っています。ライブラリだと内部にコンペ固有の変更を入れるのは厳しいので。\n単なる\u003ca class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%B9%A5%CB%A5%DA%A5%C3%A5%C8\"\u003eスニペット\u003c/a\u003e集にしておいて、コンペ中はゴリゴリ内部も書き換える前提で使った方が良さそう。\u003c/p\u003e\n\u003ch3\u003eやったこと\u003c/h3\u003e\n\u003cp\u003e以下は Discussion にも投稿した内容とほぼ同じですが、こちらにも書いておきます。\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://guruguru.ml/competitions/10/discussions/34d99be1-ab52-4868-a46c-45a24fac8308/\"\u003e\u0026#x3050;\u0026#x308B;\u0026#x3050;\u0026#x308B;\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e中盤まで CV スコアすら安定せず、ちょっとシードを変えるだけで大きくスコアが変動してしまっていました。\nそのため、正直何が効いていて何が効かなかったのかの判断を誤っていた可能性が高いです...\u003c/p\u003e\n\u003cp\u003e何をやっても安定しなかったので、最終盤にやけになってアンサンブルで誤魔化す作戦に出たのですが、これは結果的によかったと思います。\n特に、CV がある程度安定して比較可能になったおかげで、打つべき手の選択を見誤り辛くなったのが大きかったです。\n逆にいえばもっと早くこれをやっておけば、もう少し良いモデルを作れたかも？と反省しています。次回に活かしたいです。\u003c/p\u003e\n\u003cp\u003e最終サブは CNN と、それをベースに stacking した LightGBM の 2 つを出していました。\u003c/p\u003e\n\u003ch4\u003eCNN\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e正規化 / Scaling を全くせずナイーブに Conv1D ベースの NN に突っ込む\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003e((Skip Connection + Conv1D (kernel_size=5) → BatchNorm (or GroupNorm) → ReLU) * 2 → AveragePooling1D (pool_size=2, strides=2)) * 3 → GlobalAveragePooling と GlobalMaxPooling の concat\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eテーブル特徴量は \u003ca class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/MLP\"\u003eMLP\u003c/a\u003e を通して CNN の出力に Concatenate した\n\u003cul\u003e\n\u003cli\u003e採用した特徴量は beta, \u003ca class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/rms\"\u003erms\u003c/a\u003e, params1 ~ 6, tsfresh の特徴量たちの中から LightGBM での feature importance が上位 100 以内だったものを取ってきただけ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eテーブル特徴量を \u003ca class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/MLP\"\u003eMLP\u003c/a\u003e に通したものを CNN の途中でに足したらなぜかスコアが上がったので採用\n\u003cul\u003e\n\u003cli\u003e本当はテーブル特徴量を使って、どの領域に注目するかの Attention の計算をしようと思っていたが、そちらはスコアが上がらず...\u003c/li\u003e\n\u003cli\u003e悔しいので惰性で試した加算がなぜか効いた\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e始めは BN を使っていたが安定しなかった。極端に大きい入力が入ってきたときに BN の statistics がぶっ飛ぶのが悪いのでは、とあたりをつけて GN に変更したところ、伸びはしなかったが安定性が増したように見えたので採用。\u003c/li\u003e\n\u003cli\u003eOptimizer は AdamW を使っていたが安定しなかったので、SWA / Lookahead を試したところどちらも安定性の向上を確認できた。最終性能はほぼ変わらなかったが、Lookahead の方が収束が速かったのと個人的に好きだったので採用。\n\u003cul\u003e\n\u003cli\u003eLookahead 採用後は BN でも安定したので、最終的には BN / GN 両方のモデルを作って rank average した。\u003c/li\u003e\n\u003cli\u003e\u0026amp; CosineDecay with linear warmup\u003c/li\u003e\n\u003cli\u003eval prauc で early stopping\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e学習中に checkpoint をとっておき、val loss がよかった 5 epoch 分のモデルの出力の平均を使用\u003c/li\u003e\n\u003cli\u003eclass weight つき binary crossentropy loss\n\u003cul\u003e\n\u003cli\u003eclass imbalance については \u003ca href=\"https://www.tensorflow.org/tutorials/structured_data/imbalanced_data#train_on_the_oversampled_data\"\u003ehttps://www.tensorflow.org/tutorials/structured_data/imbalanced_data#train_on_the_oversampled_data\u003c/a\u003e をベースに戦略を立てていました\u003c/li\u003e\n\u003cli\u003eいくつか試しましたが、結局シンプルな class weight が一番よかったです\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eCV 戦略は StratifiedKFold(k=5)\n\u003cul\u003e\n\u003cli\u003eタスク的には StratifiedKFold じゃまずそうと思いつつも、Group, StratifiedGroup は CV / LB の相関が取れなかったのと、seed を変えた時の暴れ方がすごくて断念\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4\u003eLightGBM\u003c/h4\u003e\n\u003cp\u003eこちらは最終日にもう何も思い付かず、とはいえサブを余らせて終わるのも悔しかったので、やってみるかぁという惰性で挑戦したものでした。\nCV は Stacking した LightGBM の方がかなり高かったので興奮したのですが、流石に怖かったので CNN も提出していました。\n結論としてはどちらも  Public / Private 共にほぼ差はなかったです。\u003c/p\u003e\n\u003cp\u003e時間がなかったのであまり検証はできず、勘で良さそうな構成を選ぶしかなかったのですが、最終的に採用したのは以下のような構成です。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eCNN (BN, GN) の出力を rank にしたもの + テーブル特徴量全部盛り\u003c/li\u003e\n\u003cli\u003eoptuna の LightGBMCVTuner でハイパラ選択\u003c/li\u003e\n\u003cli\u003e2 Seed Average (Rank Average)\u003c/li\u003e\n\u003cli\u003eimbalance 対策は undersampling + bagging\n\u003cul\u003e\n\u003cli\u003e1 : 10 になるように undersampling したデータで普通に 20 モデル作り、単純に平均をとった\u003c/li\u003e\n\u003cli\u003e1:1 にしたり \u003ccode\u003eis_unbalance=True\u003c/code\u003e にしたりいくつか実験しましたが、これがもっとも CV が高かったです\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eうまくいかなかったこと\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eAttention\n\u003cul\u003e\n\u003cli\u003eTransformer ベースのモデルと、Conv ベースモデルに MultiHeadAttention を足したものの両方を試しましたが、どちらも work せず\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eSqueeze and Excitation\u003c/li\u003e\n\u003cli\u003eSeparableConv1D にして層を増やす\u003c/li\u003e\n\u003cli\u003eKernel Size を増やす\u003c/li\u003e\n\u003cli\u003eNN で Undersampling + Bagging\u003c/li\u003e\n\u003cli\u003e生データの scaling\n\u003cul\u003e\n\u003cli\u003eStandardize や 99.9%ile で clip した方が学習は安定したが、スコアがものすごく下がった...\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e(Denoising) Variational Auto Encoder\n\u003cul\u003e\n\u003cli\u003etrain/test で chip が違うことがわかっていたので、教師なし事前学習 → \u003ca class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/finetune\"\u003efinetune\u003c/a\u003e したら LB 上がるのでは、という目論見\u003c/li\u003e\n\u003cli\u003eReconstruction Error と Encoder の出力 64 次元ベクトルを LightGBM に食わせるのも試したが work せず\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%C8%F9%CA%AC\"\u003e微分\u003c/a\u003eして入力チャネルに追加して CNN に通す\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003chr\u003e\n","meta":{"rawMarkdown":"---\ntitle: \"atmaCup #5 に参加してきて Private 29 位（Public 27 位）でした！\"\ndate: 2020-06-07T11:00:00.000Z\ntags: []\n---\n\n\u003cp\u003eatmaCup #5 に参加してきました！\n\u003ciframe src=\"https://hatenablog-parts.com/embed?url=https%3A%2F%2Fatma.connpass.com%2Fevent%2F175139%2F\" title=\"【おうちで】atmaCup オンサイトデータコンペ#5 (2020/05/29 18:00〜)\" class=\"embed-card embed-webcard\" scrolling=\"no\" frameborder=\"0\" style=\"display: block; width: 100%; height: 155px; max-width: 500px; margin: 10px 0px;\"\u003e\u003c/iframe\u003e\u003ccite class=\"hatena-citation\"\u003e\u003ca href=\"https://atma.connpass.com/event/175139/\"\u003eatma.connpass.com\u003c/a\u003e\u003c/cite\u003e\u003c/p\u003e\n\n\u003cp\u003eKaggle 以外のコンペに参加したのは初めてだったのですが、お祭り感があってとても楽しかったです！\n参加者・運営全体で盛り上げていく雰囲気があったので、初参加でしたが最後までモチベーション高く取り組み続けることができました。\n\u003ca class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/Twitter\"\u003eTwitter\u003c/a\u003e TL でよく見かける方々と競えるので燃えました。\u003c/p\u003e\n\n\u003cp\u003e運営のみなさま、本当にありがとうございました！ぜひまた参加したいです！\u003c/p\u003e\n\n\u003ch3\u003e問題設定\u003c/h3\u003e\n\n\u003cp\u003e2 値分類タスクで、評価指標は PR-AUC でした。\n正例が少なく、指標も PR-AUC だったので、CV / LB が安定しなかったのが悩ましいところでした。\u003c/p\u003e\n\n\u003ch3\u003eコンペ中の動き\u003c/h3\u003e\n\n\u003cp\u003e1 週間の開催で短期決戦だったので、\u003ca class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%C9%A5%E1%A5%A4%A5%F3\"\u003eドメイン\u003c/a\u003e知識の獲得から始める余裕はないと判断して、CNN 様に抽出していただく戦略を取りました。（結果的にそこそこ NN チューニングに時間を使ったので、\u003ca class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%C9%A5%E1%A5%A4%A5%F3\"\u003eドメイン\u003c/a\u003e知識をちゃんと学びに行けばよかったとやや後悔しています）\nまた、短期決戦前提の書き殴り実験をしまくってしまったので、自分が何をやっていたのか正確な記録が無く終盤若干混乱しました。1 週間だったのでギリギリなんとかなりましたが、Kaggle みたいな長期戦は厳しそうなので、そっちに挑む際はもうちょっと丁寧に生きた方が良さそう。仮に入賞したとしても再現できるようにするコストがものすごく高い実装になってしまっていました...\u003c/p\u003e\n\n\u003cp\u003e実験管理を mlflow でやったのですが、結構よかったです。\n最終日はローカルを投げ捨てて \u003ca class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/GPU\"\u003eGPU\u003c/a\u003e 使い始めたので、今までローカルに積み上げてきた実験との比較が若干厄介でした。（統合せず、別の \u003ccode\u003emlflow ui\u003c/code\u003e をタブで開いて眺めていました...）\nただ、CV 戦略を変えたり評価指標をいじったときに、同条件で単純比較できない実験にもかかわらずそれが同じテーブルに並んでしまうのが悩ましいなと思いました。\n時系列で並んでいるうちは良いのですが、指標ごとにソートすると本当にどれが信じられる結果なのかわかり辛くなってしまいました。\nこのあたりはタグなどを活用すると良いのかもしれない？もしくは CV などの設計が変わった時点できちんと experiment のレベルで分離すべきだった気がします。\u003c/p\u003e\n\n\u003cp\u003eまた、実は事前にちょこっとだけ準備していて、「学習データ、テストデータ、CV、モデル、評価関数」あたりを渡すと mlflow にログを書きつつ CV 評価して oof と test の prediction をはく薄い wrapper を書いていました。\n最初はまぁ使えていたんですが、NN のことを全く想定していなかったので NN に移った時点で全く使えなくなってしまったのと、細かいことをやりだすとやっぱり wrap された内部に手を入れたくなってしまって厳しかったです。\n予想はしていたので相当薄めに作ったつもりだったのですが、それでもこうなっちゃうか〜という感じでちょっと辛い。\nライブラリとしての作りにしたのが間違いだったのかもと思っています。ライブラリだと内部にコンペ固有の変更を入れるのは厳しいので。\n単なる\u003ca class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%B9%A5%CB%A5%DA%A5%C3%A5%C8\"\u003eスニペット\u003c/a\u003e集にしておいて、コンペ中はゴリゴリ内部も書き換える前提で使った方が良さそう。\u003c/p\u003e\n\n\u003ch3\u003eやったこと\u003c/h3\u003e\n\n\u003cp\u003e以下は Discussion にも投稿した内容とほぼ同じですが、こちらにも書いておきます。\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"https://guruguru.ml/competitions/10/discussions/34d99be1-ab52-4868-a46c-45a24fac8308/\"\u003e\u0026#x3050;\u0026#x308B;\u0026#x3050;\u0026#x308B;\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003e中盤まで CV スコアすら安定せず、ちょっとシードを変えるだけで大きくスコアが変動してしまっていました。\nそのため、正直何が効いていて何が効かなかったのかの判断を誤っていた可能性が高いです...\u003c/p\u003e\n\n\u003cp\u003e何をやっても安定しなかったので、最終盤にやけになってアンサンブルで誤魔化す作戦に出たのですが、これは結果的によかったと思います。\n特に、CV がある程度安定して比較可能になったおかげで、打つべき手の選択を見誤り辛くなったのが大きかったです。\n逆にいえばもっと早くこれをやっておけば、もう少し良いモデルを作れたかも？と反省しています。次回に活かしたいです。\u003c/p\u003e\n\n\u003cp\u003e最終サブは CNN と、それをベースに stacking した LightGBM の 2 つを出していました。\u003c/p\u003e\n\n\u003ch4\u003eCNN\u003c/h4\u003e\n\n\u003cul\u003e\n\u003cli\u003e正規化 / Scaling を全くせずナイーブに Conv1D ベースの NN に突っ込む\n\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003e((Skip Connection + Conv1D (kernel_size=5) → BatchNorm (or GroupNorm) → ReLU) * 2 → AveragePooling1D (pool_size=2, strides=2)) * 3 → GlobalAveragePooling と GlobalMaxPooling の concat\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eテーブル特徴量は \u003ca class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/MLP\"\u003eMLP\u003c/a\u003e を通して CNN の出力に Concatenate した\n\n\u003cul\u003e\n\u003cli\u003e採用した特徴量は beta, \u003ca class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/rms\"\u003erms\u003c/a\u003e, params1 ~ 6, tsfresh の特徴量たちの中から LightGBM での feature importance が上位 100 以内だったものを取ってきただけ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eテーブル特徴量を \u003ca class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/MLP\"\u003eMLP\u003c/a\u003e に通したものを CNN の途中でに足したらなぜかスコアが上がったので採用\n\n\u003cul\u003e\n\u003cli\u003e本当はテーブル特徴量を使って、どの領域に注目するかの Attention の計算をしようと思っていたが、そちらはスコアが上がらず...\u003c/li\u003e\n\u003cli\u003e悔しいので惰性で試した加算がなぜか効いた\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e始めは BN を使っていたが安定しなかった。極端に大きい入力が入ってきたときに BN の statistics がぶっ飛ぶのが悪いのでは、とあたりをつけて GN に変更したところ、伸びはしなかったが安定性が増したように見えたので採用。\u003c/li\u003e\n\u003cli\u003eOptimizer は AdamW を使っていたが安定しなかったので、SWA / Lookahead を試したところどちらも安定性の向上を確認できた。最終性能はほぼ変わらなかったが、Lookahead の方が収束が速かったのと個人的に好きだったので採用。\n\n\u003cul\u003e\n\u003cli\u003eLookahead 採用後は BN でも安定したので、最終的には BN / GN 両方のモデルを作って rank average した。\u003c/li\u003e\n\u003cli\u003e\u0026amp; CosineDecay with linear warmup\u003c/li\u003e\n\u003cli\u003eval prauc で early stopping\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e学習中に checkpoint をとっておき、val loss がよかった 5 epoch 分のモデルの出力の平均を使用\u003c/li\u003e\n\u003cli\u003eclass weight つき binary crossentropy loss\n\n\u003cul\u003e\n\u003cli\u003eclass imbalance については \u003ca href=\"https://www.tensorflow.org/tutorials/structured_data/imbalanced_data#train_on_the_oversampled_data\"\u003ehttps://www.tensorflow.org/tutorials/structured_data/imbalanced_data#train_on_the_oversampled_data\u003c/a\u003e をベースに戦略を立てていました\u003c/li\u003e\n\u003cli\u003eいくつか試しましたが、結局シンプルな class weight が一番よかったです\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eCV 戦略は StratifiedKFold(k=5)\n\n\u003cul\u003e\n\u003cli\u003eタスク的には StratifiedKFold じゃまずそうと思いつつも、Group, StratifiedGroup は CV / LB の相関が取れなかったのと、seed を変えた時の暴れ方がすごくて断念\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch4\u003eLightGBM\u003c/h4\u003e\n\n\u003cp\u003eこちらは最終日にもう何も思い付かず、とはいえサブを余らせて終わるのも悔しかったので、やってみるかぁという惰性で挑戦したものでした。\nCV は Stacking した LightGBM の方がかなり高かったので興奮したのですが、流石に怖かったので CNN も提出していました。\n結論としてはどちらも  Public / Private 共にほぼ差はなかったです。\u003c/p\u003e\n\n\u003cp\u003e時間がなかったのであまり検証はできず、勘で良さそうな構成を選ぶしかなかったのですが、最終的に採用したのは以下のような構成です。\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eCNN (BN, GN) の出力を rank にしたもの + テーブル特徴量全部盛り\u003c/li\u003e\n\u003cli\u003eoptuna の LightGBMCVTuner でハイパラ選択\u003c/li\u003e\n\u003cli\u003e2 Seed Average (Rank Average)\u003c/li\u003e\n\u003cli\u003eimbalance 対策は undersampling + bagging\n\n\u003cul\u003e\n\u003cli\u003e1 : 10 になるように undersampling したデータで普通に 20 モデル作り、単純に平均をとった\u003c/li\u003e\n\u003cli\u003e1:1 にしたり \u003ccode\u003eis_unbalance=True\u003c/code\u003e にしたりいくつか実験しましたが、これがもっとも CV が高かったです\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch3\u003eうまくいかなかったこと\u003c/h3\u003e\n\n\u003cul\u003e\n\u003cli\u003eAttention\n\n\u003cul\u003e\n\u003cli\u003eTransformer ベースのモデルと、Conv ベースモデルに MultiHeadAttention を足したものの両方を試しましたが、どちらも work せず\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eSqueeze and Excitation\u003c/li\u003e\n\u003cli\u003eSeparableConv1D にして層を増やす\u003c/li\u003e\n\u003cli\u003eKernel Size を増やす\u003c/li\u003e\n\u003cli\u003eNN で Undersampling + Bagging\u003c/li\u003e\n\u003cli\u003e生データの scaling\n\n\u003cul\u003e\n\u003cli\u003eStandardize や 99.9%ile で clip した方が学習は安定したが、スコアがものすごく下がった...\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e(Denoising) Variational Auto Encoder\n\n\u003cul\u003e\n\u003cli\u003etrain/test で chip が違うことがわかっていたので、教師なし事前学習 → \u003ca class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/finetune\"\u003efinetune\u003c/a\u003e したら LB 上がるのでは、という目論見\u003c/li\u003e\n\u003cli\u003eReconstruction Error と Encoder の出力 64 次元ベクトルを LightGBM に食わせるのも試したが work せず\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%C8%F9%CA%AC\"\u003e微分\u003c/a\u003eして入力チャネルに追加して CNN に通す\u003c/li\u003e\n\u003c/ul\u003e\n\n---\n\n---\n","contentMarkdown":"\n\u003cp\u003eatmaCup #5 に参加してきました！\n\u003ciframe src=\"https://hatenablog-parts.com/embed?url=https%3A%2F%2Fatma.connpass.com%2Fevent%2F175139%2F\" title=\"【おうちで】atmaCup オンサイトデータコンペ#5 (2020/05/29 18:00〜)\" class=\"embed-card embed-webcard\" scrolling=\"no\" frameborder=\"0\" style=\"display: block; width: 100%; height: 155px; max-width: 500px; margin: 10px 0px;\"\u003e\u003c/iframe\u003e\u003ccite class=\"hatena-citation\"\u003e\u003ca href=\"https://atma.connpass.com/event/175139/\"\u003eatma.connpass.com\u003c/a\u003e\u003c/cite\u003e\u003c/p\u003e\n\n\u003cp\u003eKaggle 以外のコンペに参加したのは初めてだったのですが、お祭り感があってとても楽しかったです！\n参加者・運営全体で盛り上げていく雰囲気があったので、初参加でしたが最後までモチベーション高く取り組み続けることができました。\n\u003ca class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/Twitter\"\u003eTwitter\u003c/a\u003e TL でよく見かける方々と競えるので燃えました。\u003c/p\u003e\n\n\u003cp\u003e運営のみなさま、本当にありがとうございました！ぜひまた参加したいです！\u003c/p\u003e\n\n\u003ch3\u003e問題設定\u003c/h3\u003e\n\n\u003cp\u003e2 値分類タスクで、評価指標は PR-AUC でした。\n正例が少なく、指標も PR-AUC だったので、CV / LB が安定しなかったのが悩ましいところでした。\u003c/p\u003e\n\n\u003ch3\u003eコンペ中の動き\u003c/h3\u003e\n\n\u003cp\u003e1 週間の開催で短期決戦だったので、\u003ca class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%C9%A5%E1%A5%A4%A5%F3\"\u003eドメイン\u003c/a\u003e知識の獲得から始める余裕はないと判断して、CNN 様に抽出していただく戦略を取りました。（結果的にそこそこ NN チューニングに時間を使ったので、\u003ca class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%C9%A5%E1%A5%A4%A5%F3\"\u003eドメイン\u003c/a\u003e知識をちゃんと学びに行けばよかったとやや後悔しています）\nまた、短期決戦前提の書き殴り実験をしまくってしまったので、自分が何をやっていたのか正確な記録が無く終盤若干混乱しました。1 週間だったのでギリギリなんとかなりましたが、Kaggle みたいな長期戦は厳しそうなので、そっちに挑む際はもうちょっと丁寧に生きた方が良さそう。仮に入賞したとしても再現できるようにするコストがものすごく高い実装になってしまっていました...\u003c/p\u003e\n\n\u003cp\u003e実験管理を mlflow でやったのですが、結構よかったです。\n最終日はローカルを投げ捨てて \u003ca class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/GPU\"\u003eGPU\u003c/a\u003e 使い始めたので、今までローカルに積み上げてきた実験との比較が若干厄介でした。（統合せず、別の \u003ccode\u003emlflow ui\u003c/code\u003e をタブで開いて眺めていました...）\nただ、CV 戦略を変えたり評価指標をいじったときに、同条件で単純比較できない実験にもかかわらずそれが同じテーブルに並んでしまうのが悩ましいなと思いました。\n時系列で並んでいるうちは良いのですが、指標ごとにソートすると本当にどれが信じられる結果なのかわかり辛くなってしまいました。\nこのあたりはタグなどを活用すると良いのかもしれない？もしくは CV などの設計が変わった時点できちんと experiment のレベルで分離すべきだった気がします。\u003c/p\u003e\n\n\u003cp\u003eまた、実は事前にちょこっとだけ準備していて、「学習データ、テストデータ、CV、モデル、評価関数」あたりを渡すと mlflow にログを書きつつ CV 評価して oof と test の prediction をはく薄い wrapper を書いていました。\n最初はまぁ使えていたんですが、NN のことを全く想定していなかったので NN に移った時点で全く使えなくなってしまったのと、細かいことをやりだすとやっぱり wrap された内部に手を入れたくなってしまって厳しかったです。\n予想はしていたので相当薄めに作ったつもりだったのですが、それでもこうなっちゃうか〜という感じでちょっと辛い。\nライブラリとしての作りにしたのが間違いだったのかもと思っています。ライブラリだと内部にコンペ固有の変更を入れるのは厳しいので。\n単なる\u003ca class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%A5%B9%A5%CB%A5%DA%A5%C3%A5%C8\"\u003eスニペット\u003c/a\u003e集にしておいて、コンペ中はゴリゴリ内部も書き換える前提で使った方が良さそう。\u003c/p\u003e\n\n\u003ch3\u003eやったこと\u003c/h3\u003e\n\n\u003cp\u003e以下は Discussion にも投稿した内容とほぼ同じですが、こちらにも書いておきます。\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"https://guruguru.ml/competitions/10/discussions/34d99be1-ab52-4868-a46c-45a24fac8308/\"\u003e\u0026#x3050;\u0026#x308B;\u0026#x3050;\u0026#x308B;\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003e中盤まで CV スコアすら安定せず、ちょっとシードを変えるだけで大きくスコアが変動してしまっていました。\nそのため、正直何が効いていて何が効かなかったのかの判断を誤っていた可能性が高いです...\u003c/p\u003e\n\n\u003cp\u003e何をやっても安定しなかったので、最終盤にやけになってアンサンブルで誤魔化す作戦に出たのですが、これは結果的によかったと思います。\n特に、CV がある程度安定して比較可能になったおかげで、打つべき手の選択を見誤り辛くなったのが大きかったです。\n逆にいえばもっと早くこれをやっておけば、もう少し良いモデルを作れたかも？と反省しています。次回に活かしたいです。\u003c/p\u003e\n\n\u003cp\u003e最終サブは CNN と、それをベースに stacking した LightGBM の 2 つを出していました。\u003c/p\u003e\n\n\u003ch4\u003eCNN\u003c/h4\u003e\n\n\u003cul\u003e\n\u003cli\u003e正規化 / Scaling を全くせずナイーブに Conv1D ベースの NN に突っ込む\n\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003e((Skip Connection + Conv1D (kernel_size=5) → BatchNorm (or GroupNorm) → ReLU) * 2 → AveragePooling1D (pool_size=2, strides=2)) * 3 → GlobalAveragePooling と GlobalMaxPooling の concat\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eテーブル特徴量は \u003ca class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/MLP\"\u003eMLP\u003c/a\u003e を通して CNN の出力に Concatenate した\n\n\u003cul\u003e\n\u003cli\u003e採用した特徴量は beta, \u003ca class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/rms\"\u003erms\u003c/a\u003e, params1 ~ 6, tsfresh の特徴量たちの中から LightGBM での feature importance が上位 100 以内だったものを取ってきただけ\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eテーブル特徴量を \u003ca class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/MLP\"\u003eMLP\u003c/a\u003e に通したものを CNN の途中でに足したらなぜかスコアが上がったので採用\n\n\u003cul\u003e\n\u003cli\u003e本当はテーブル特徴量を使って、どの領域に注目するかの Attention の計算をしようと思っていたが、そちらはスコアが上がらず...\u003c/li\u003e\n\u003cli\u003e悔しいので惰性で試した加算がなぜか効いた\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e始めは BN を使っていたが安定しなかった。極端に大きい入力が入ってきたときに BN の statistics がぶっ飛ぶのが悪いのでは、とあたりをつけて GN に変更したところ、伸びはしなかったが安定性が増したように見えたので採用。\u003c/li\u003e\n\u003cli\u003eOptimizer は AdamW を使っていたが安定しなかったので、SWA / Lookahead を試したところどちらも安定性の向上を確認できた。最終性能はほぼ変わらなかったが、Lookahead の方が収束が速かったのと個人的に好きだったので採用。\n\n\u003cul\u003e\n\u003cli\u003eLookahead 採用後は BN でも安定したので、最終的には BN / GN 両方のモデルを作って rank average した。\u003c/li\u003e\n\u003cli\u003e\u0026amp; CosineDecay with linear warmup\u003c/li\u003e\n\u003cli\u003eval prauc で early stopping\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e学習中に checkpoint をとっておき、val loss がよかった 5 epoch 分のモデルの出力の平均を使用\u003c/li\u003e\n\u003cli\u003eclass weight つき binary crossentropy loss\n\n\u003cul\u003e\n\u003cli\u003eclass imbalance については \u003ca href=\"https://www.tensorflow.org/tutorials/structured_data/imbalanced_data#train_on_the_oversampled_data\"\u003ehttps://www.tensorflow.org/tutorials/structured_data/imbalanced_data#train_on_the_oversampled_data\u003c/a\u003e をベースに戦略を立てていました\u003c/li\u003e\n\u003cli\u003eいくつか試しましたが、結局シンプルな class weight が一番よかったです\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eCV 戦略は StratifiedKFold(k=5)\n\n\u003cul\u003e\n\u003cli\u003eタスク的には StratifiedKFold じゃまずそうと思いつつも、Group, StratifiedGroup は CV / LB の相関が取れなかったのと、seed を変えた時の暴れ方がすごくて断念\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch4\u003eLightGBM\u003c/h4\u003e\n\n\u003cp\u003eこちらは最終日にもう何も思い付かず、とはいえサブを余らせて終わるのも悔しかったので、やってみるかぁという惰性で挑戦したものでした。\nCV は Stacking した LightGBM の方がかなり高かったので興奮したのですが、流石に怖かったので CNN も提出していました。\n結論としてはどちらも  Public / Private 共にほぼ差はなかったです。\u003c/p\u003e\n\n\u003cp\u003e時間がなかったのであまり検証はできず、勘で良さそうな構成を選ぶしかなかったのですが、最終的に採用したのは以下のような構成です。\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eCNN (BN, GN) の出力を rank にしたもの + テーブル特徴量全部盛り\u003c/li\u003e\n\u003cli\u003eoptuna の LightGBMCVTuner でハイパラ選択\u003c/li\u003e\n\u003cli\u003e2 Seed Average (Rank Average)\u003c/li\u003e\n\u003cli\u003eimbalance 対策は undersampling + bagging\n\n\u003cul\u003e\n\u003cli\u003e1 : 10 になるように undersampling したデータで普通に 20 モデル作り、単純に平均をとった\u003c/li\u003e\n\u003cli\u003e1:1 にしたり \u003ccode\u003eis_unbalance=True\u003c/code\u003e にしたりいくつか実験しましたが、これがもっとも CV が高かったです\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch3\u003eうまくいかなかったこと\u003c/h3\u003e\n\n\u003cul\u003e\n\u003cli\u003eAttention\n\n\u003cul\u003e\n\u003cli\u003eTransformer ベースのモデルと、Conv ベースモデルに MultiHeadAttention を足したものの両方を試しましたが、どちらも work せず\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eSqueeze and Excitation\u003c/li\u003e\n\u003cli\u003eSeparableConv1D にして層を増やす\u003c/li\u003e\n\u003cli\u003eKernel Size を増やす\u003c/li\u003e\n\u003cli\u003eNN で Undersampling + Bagging\u003c/li\u003e\n\u003cli\u003e生データの scaling\n\n\u003cul\u003e\n\u003cli\u003eStandardize や 99.9%ile で clip した方が学習は安定したが、スコアがものすごく下がった...\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e(Denoising) Variational Auto Encoder\n\n\u003cul\u003e\n\u003cli\u003etrain/test で chip が違うことがわかっていたので、教師なし事前学習 → \u003ca class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/finetune\"\u003efinetune\u003c/a\u003e したら LB 上がるのでは、という目論見\u003c/li\u003e\n\u003cli\u003eReconstruction Error と Encoder の出力 64 次元ベクトルを LightGBM に食わせるのも試したが work せず\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca class=\"keyword\" href=\"http://d.hatena.ne.jp/keyword/%C8%F9%CA%AC\"\u003e微分\u003c/a\u003eして入力チャネルに追加して CNN に通す\u003c/li\u003e\n\u003c/ul\u003e\n\n---\n\n---\n","slug":"atmacup5th","title":"atmaCup #5 に参加してきて Private 29 位（Public 27 位）でした！","timestamp":1591527600000,"tags":[]}}},"__N_SSG":true},"page":"/posts/[slug]","query":{"slug":"atmacup5th"},"buildId":"LTCqLRPEd5Qd2agqEQJZo","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>